"use strict";
var __extends = (this && this.__extends) || (function () {
    var extendStatics = function (d, b) {
        extendStatics = Object.setPrototypeOf ||
            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };
        return extendStatics(d, b);
    };
    return function (d, b) {
        extendStatics(d, b);
        function __() { this.constructor = d; }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
})();
var __makeTemplateObject = (this && this.__makeTemplateObject) || function (cooked, raw) {
    if (Object.defineProperty) { Object.defineProperty(cooked, "raw", { value: raw }); } else { cooked.raw = raw; }
    return cooked;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];
    result["default"] = mod;
    return result;
};
define("util/ILogTarget", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
});
define("util/LogValue", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    /**
     * A virtual representation of a discrete value logged to from AssemblyScript.
     */
    var LogValue = /** @class */ (function () {
        function LogValue() {
            /**
             * If a pointer is referenced, this is the precise memory location of the referenced block of
             * data.
             */
            this.pointer = 0;
            /**
             * If a pointer is referenced and isn't a string, this is the size of the referenced block of
             * data.
             */
            this.offset = 0;
            /**
             * If a pointer is referenced and ins't a string, this is an array of bytes to be logged byt the
             * logger.
             */
            this.bytes = [];
            /**
             * This is a message generated by the TestSuite to be displayed in the logger.
             */
            this.message = "";
            /**
             * This is the relevant stack trace, filtered with the `/wasm/i` regex.
             */
            this.stack = "";
            /**
             * This is the referenced log target.
             */
            this.target = null;
            /**
             * This is the raw logged value.
             */
            this.value = null;
        }
        return LogValue;
    }());
    exports.LogValue = LogValue;
});
define("util/ActualValue", ["require", "exports", "util/LogValue"], function (require, exports, LogValue_1) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    /**
     * A class representing a reported expected or actual value. It shares a lot of properties with
     * LogValue, so those are copied over.
     */
    var ActualValue = /** @class */ (function (_super) {
        __extends(ActualValue, _super);
        function ActualValue() {
            var _this = _super !== null && _super.apply(this, arguments) || this;
            /**
             * An indicator if the actual expected value is negated.
             */
            _this.negated = false;
            return _this;
        }
        return ActualValue;
    }(LogValue_1.LogValue));
    exports.ActualValue = ActualValue;
});
define("test/TestResult", ["require", "exports", "mathjs"], function (require, exports, mathjs_1) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    /**
     * This is the data class that contains all the data about each `test()` or `it()` function defined
     * in the `AssemblyScript` module.
     */
    var TestResult = /** @class */ (function () {
        function TestResult() {
            /** The actual test's name or description. */
            this.name = "";
            /** The indicator to see if the test passed. */
            this.pass = false;
            /** The time in milliseconds indicating how long the test ran for each run. */
            this.times = [];
            /** The reported actual value description. */
            this.actual = null;
            /** The reported expected value description. */
            this.expected = null;
            /** If the test failed, this is the message describing why the test failed. */
            this.message = "";
            /** A set of strings logged by the test itself. */
            this.logs = [];
            /** The generated stack trace if the test errored. */
            this.stack = null;
            /** This value is set to true if the test is expected to throw. */
            this.negated = false;
            /** This value indicates if performance statistics were collected for this test. */
            this.performance = false;
            /** The number of decimal places used for rounding. */
            this.decimalPlaces = 3;
            /** This value indicates if an average was calculated. */
            this.hasAverage = false;
            /** This is the average (mean) value. */
            this.average = 0;
            /** This value indicates if a max was calculated. */
            this.hasMax = false;
            /** This is the max time. */
            this.max = 0;
            /** This value indicates if a median value was calculated. */
            this.hasMedian = false;
            /** This is the calculated median time. */
            this.median = 0;
            /** This value indicates if a min value was calculated. */
            this.hasMin = false;
            /** This is the calculated min time. */
            this.min = 0;
            /** This value indicates if a standard deviation value was calculated. */
            this.hasStdDev = false;
            /** This is the calculated standard deviation of the times collected. */
            this.stdDev = 0;
            /** A boolean indicating if the variance was calcluated. */
            this.hasVariance = false;
            /** The raw variance calculation before rounding was applied. */
            this.rawVariance = 0;
            /** This value indicates the calculated variance used for standard deviation calculations. */
            this.variance = 0;
            /** This is the timestamp for when the test started in milliseconds. */
            this.start = 0;
            /** This is the timestamp for when the test ended in milliseconds. */
            this.end = 0;
            /** This is the run time for the test in milliseconds. */
            this.runTime = 0;
        }
        /**
         * Caclculate the average value of the collected times.
         */
        TestResult.prototype.calculateAverage = function () {
            this.hasAverage = true;
            this.average = Math.round(1000 * mathjs_1.mean(this.times)) / 1000;
        };
        /**
         * Calculate the max time of the collected times.
         */
        TestResult.prototype.calculateMax = function () {
            this.hasMax = true;
            this.max = Math.max.apply(Math, this.times);
        };
        /**
         * Calculate the median value of the collected times.
         */
        TestResult.prototype.calculateMedian = function () {
            this.hasMedian = true;
            this.median = mathjs_1.round(mathjs_1.median(this.times), this.decimalPlaces);
        };
        /**
         * Calculate the min value of the collected times.
         */
        TestResult.prototype.calculateMin = function () {
            this.hasMin = true;
            this.min = Math.min.apply(Math, this.times);
        };
        /**
         * Calculate the standard deviation of the collected times.
         */
        TestResult.prototype.calculateStandardDeviation = function () {
            if (!this.hasVariance) {
                this.calculateVariance();
            }
            this.hasStdDev = true;
            this.stdDev = mathjs_1.round(Math.sqrt(this.rawVariance), this.decimalPlaces);
        };
        /**
         * Calculate the variance.
         */
        TestResult.prototype.calculateVariance = function () {
            if (this.hasVariance)
                return;
            this.hasVariance = true;
            this.rawVariance = mathjs_1.var(this.times, "biased");
            this.variance = mathjs_1.round(this.rawVariance, this.decimalPlaces);
        };
        return TestResult;
    }());
    exports.TestResult = TestResult;
});
define("test/TestGroup", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    /**
     * This test group class is designed with a data oriented layout in mind. Each test property is
     * represented by an array.
     */
    var TestGroup = /** @class */ (function () {
        function TestGroup() {
            this.describePointers = [];
            // callback properties
            this.beforeEachPointers = [];
            this.afterEachPointers = [];
            this.beforeAllPointers = [];
            this.afterAllPointers = [];
            // test properties
            this.testFunctionPointers = [];
            this.testNamePointers = [];
            this.testMessagePointers = [];
            this.testThrows = [];
            // tests and todos
            this.tests = [];
            this.todoPointers = [];
            this.todos = [];
            // logs
            this.logs = [];
            this.name = "";
            this.pass = true;
            this.reason = "";
            this.time = 0;
            // individual test performance configurations
            this.performanceEnabled = [];
            this.maxSamples = [];
            this.roundDecimalPlaces = [];
            this.maxTestRuntime = [];
            this.reportAverage = [];
            this.reportMedian = [];
            this.reportStandardDeviation = [];
            this.reportMax = [];
            this.reportMin = [];
            this.reportVariance = [];
        }
        TestGroup.prototype.fork = function () {
            var forked = new TestGroup();
            forked.describePointers = this.describePointers.slice();
            forked.beforeEachPointers = this.beforeEachPointers.slice();
            forked.afterEachPointers = this.afterEachPointers.slice();
            forked.beforeAllPointers = this.beforeAllPointers.slice();
            forked.afterAllPointers = this.afterAllPointers.slice();
            return forked;
        };
        return TestGroup;
    }());
    exports.TestGroup = TestGroup;
});
define("test/TestReporter", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    var TestReporter = /** @class */ (function () {
        function TestReporter() {
        }
        return TestReporter;
    }());
    exports.TestReporter = TestReporter;
});
define("reporter/DefaultTestReporter", ["require", "exports", "chalk", "test/TestReporter"], function (require, exports, chalk_1, TestReporter_1) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    chalk_1 = __importDefault(chalk_1);
    function stringifyActualValue(type, value) {
        if (!value)
            return "";
        var byteString = "";
        if (value.bytes.length > 0) {
            byteString = "\n               " + createReferenceString(value.bytes, value.pointer, value.offset)
                .split("\n")
                .join("\n               ");
        }
        var stackString = "\n           " + value.stack
            .split("\n")
            .join("\n           ");
        return type === 1 /* Expected */
            ? chalk_1.default(templateObject_1 || (templateObject_1 = __makeTemplateObject(["{green ", "}{blue ", "}{yellow ", "}\n"], ["{green ", "}{blue ", "}{yellow ", "}\\n"])), value.message, byteString, stackString) : chalk_1.default(templateObject_2 || (templateObject_2 = __makeTemplateObject(["{red ", "}{blue ", "}{yellow ", "}\n"], ["{red ", "}{blue ", "}{yellow ", "}\\n"])), value.message, byteString, stackString);
    }
    /**
     * This function generates a 2 digit hexadecimal string from the given number.
     *
     * @param {number} value - A number from [0-255].
     * @returns {string} - The hexadecimal string representing the byte
     */
    function hex(value) {
        var result = value.toString(16);
        if (result.length === 1)
            return "0" + result;
        return result;
    }
    /**
     * This function returns a string that formats the bytes into rows of 8 bytes with a space between
     * byte 4 and 5 on each row.
     *
     * @param {number[]} bytes - The byte array
     * @param {number} pointer - The pointer of the reference.
     * @param {number} offset - The offset of the reference.
     */
    function createReferenceString(bytes, pointer, offset) {
        var referenceEnd = pointer + offset;
        // start with a tabbed out string
        var result = "Range: [dec: " + pointer.toString() + "~" + referenceEnd.toString() + "] [hex: 0x" + pointer.toString(16) + "~0x" + referenceEnd.toString(16) + "]";
        result += "\n07 06 05 04   03 02 01 00";
        result += "\n~~~~~~~~~~~~~~~~~~~~~~~~~";
        result += "\n";
        // for each byte
        for (var i = 0; i < offset; i++) {
            // append a byte and an empty space
            result += hex(bytes[i]) + " ";
            if (i % 8 === 7) {
                // every 8 characters add a newline
                result += "\n";
            }
            else if (i % 4 === 3) {
                // every 4 characters add an extra two spaces
                result += "  ";
            }
        }
        // remove leading space
        return result.trimRight();
    }
    var groupLogIndex = new WeakMap();
    var DefaultTestReporter = /** @class */ (function (_super) {
        __extends(DefaultTestReporter, _super);
        function DefaultTestReporter() {
            return _super !== null && _super.apply(this, arguments) || this;
        }
        DefaultTestReporter.prototype.onStart = function (_suite) {
        };
        DefaultTestReporter.prototype.onGroupStart = function (group) {
            console.log("");
            console.log(chalk_1.default(templateObject_3 || (templateObject_3 = __makeTemplateObject(["[Describe]: ", ""], ["[Describe]: ", ""])), group.name));
            console.log("");
            for (var _i = 0, _a = group.logs; _i < _a.length; _i++) {
                var logValue = _a[_i];
                this.onLog(logValue);
            }
            groupLogIndex.set(group, group.logs.length);
        };
        DefaultTestReporter.prototype.onGroupFinish = function (group) {
            var result = group.pass
                ? chalk_1.default(templateObject_4 || (templateObject_4 = __makeTemplateObject(["{green \u2714 PASS}"], ["{green \u2714 PASS}"]))) : chalk_1.default(templateObject_5 || (templateObject_5 = __makeTemplateObject(["{red \u2716 FAIL}"], ["{red \u2716 FAIL}"])));
            var todoCount = group.todos.length;
            var successCount = group.tests.filter(function (e) { return e.pass; }).length;
            var count = group.tests.length;
            for (var _i = 0, _a = group.logs.slice(groupLogIndex.get(group) || 0); _i < _a.length; _i++) {
                var logValue = _a[_i];
                this.onLog(logValue);
            }
            console.log("");
            console.log(chalk_1.default(templateObject_6 || (templateObject_6 = __makeTemplateObject(["  [Result]: ", ""], ["  [Result]: ", ""])), result));
            console.log(chalk_1.default(templateObject_7 || (templateObject_7 = __makeTemplateObject(["   [Tests]: ", " pass, ", " fail, ", " total"], ["   [Tests]: ", " pass, ", " fail, ", " total"])), successCount.toString(), (count - successCount).toString(), count.toString()));
            console.log(chalk_1.default(templateObject_8 || (templateObject_8 = __makeTemplateObject(["    [Todo]: ", " tests"], ["    [Todo]: ", " tests"])), todoCount.toString()));
            console.log(chalk_1.default(templateObject_9 || (templateObject_9 = __makeTemplateObject(["    [Time]: ", "ms"], ["    [Time]: ", "ms"])), group.time.toString()));
        };
        DefaultTestReporter.prototype.onTestStart = function (_group, _test) { };
        DefaultTestReporter.prototype.onTestFinish = function (_group, test) {
            if (test.pass) {
                console.log(chalk_1.default(templateObject_10 || (templateObject_10 = __makeTemplateObject([" {green [Success]: \u2714} ", ""], [" {green [Success]: \u2714} ", ""])), test.name));
            }
            else {
                console.log(chalk_1.default(templateObject_11 || (templateObject_11 = __makeTemplateObject(["    {red [Fail]: \u2716} ", ""], ["    {red [Fail]: \u2716} ", ""])), test.name));
                console.log("");
                if (!test.negated) {
                    console.log("   [Actual]: " + stringifyActualValue(0 /* Actual */, test.actual));
                    console.log(" [Expected]: " + stringifyActualValue(1 /* Expected */, test.expected));
                }
                if (test.message) {
                    console.log(chalk_1.default(templateObject_12 || (templateObject_12 = __makeTemplateObject(["  [Message]: {yellow ", "}"], ["  [Message]: {yellow ", "}"])), test.message));
                }
                if (test.stack) {
                    console.log("    [Stack]: " + test.stack.split("\n").join("\n           "));
                }
            }
            if (test.performance) {
                console.log(chalk_1.default(templateObject_13 || (templateObject_13 = __makeTemplateObject([" {yellow [Samples]}: ", ""], [" {yellow [Samples]}: ", ""])), test.times.length.toString()));
                // log statistics
                if (test.hasAverage) {
                    console.log(chalk_1.default(templateObject_14 || (templateObject_14 = __makeTemplateObject(["    {yellow [Mean]}: ", "ms"], ["    {yellow [Mean]}: ", "ms"])), test.average.toString()));
                }
                if (test.hasMedian) {
                    console.log(chalk_1.default(templateObject_15 || (templateObject_15 = __makeTemplateObject(["  {yellow [Median]}: ", "ms"], ["  {yellow [Median]}: ", "ms"])), test.median.toString()));
                }
                if (test.hasVariance) {
                    console.log(chalk_1.default(templateObject_16 || (templateObject_16 = __makeTemplateObject(["{yellow [Variance]}: ", "ms"], ["{yellow [Variance]}: ", "ms"])), test.variance.toString()));
                }
                if (test.hasStdDev) {
                    console.log(chalk_1.default(templateObject_17 || (templateObject_17 = __makeTemplateObject(["  {yellow [StdDev]}: ", "ms"], ["  {yellow [StdDev]}: ", "ms"])), test.stdDev.toString()));
                }
                if (test.hasMax) {
                    console.log(chalk_1.default(templateObject_18 || (templateObject_18 = __makeTemplateObject(["     {yellow [Max]}: ", "ms"], ["     {yellow [Max]}: ", "ms"])), test.max.toString()));
                }
                if (test.hasMin) {
                    console.log(chalk_1.default(templateObject_19 || (templateObject_19 = __makeTemplateObject(["     {yellow [Min]}: ", "ms"], ["     {yellow [Min]}: ", "ms"])), test.min.toString()));
                }
            }
            else {
                // log the log values
                for (var _i = 0, _a = test.logs; _i < _a.length; _i++) {
                    var logValue = _a[_i];
                    this.onLog(logValue);
                }
            }
        };
        DefaultTestReporter.prototype.onFinish = function (suite) {
            var result = suite.pass
                ? chalk_1.default(templateObject_20 || (templateObject_20 = __makeTemplateObject(["{green \u2714 Pass}"], ["{green \u2714 Pass}"]))) : chalk_1.default(templateObject_21 || (templateObject_21 = __makeTemplateObject(["{red \u2716 Fail}"], ["{red \u2716 Fail}"])));
            var count = suite.testGroups
                .map(function (e) { return e.tests.length; })
                .reduce(function (a, b) { return a + b; }, 0);
            var successCount = suite.testGroups
                .map(function (e) { return e.tests.filter(function (f) { return f.pass; }).length; })
                .reduce(function (a, b) { return a + b; }, 0);
            console.log("");
            console.log("~".repeat(process.stdout.columns - 10));
            console.log("");
            console.log(chalk_1.default(templateObject_22 || (templateObject_22 = __makeTemplateObject(["    [File]: ", ""], ["    [File]: ", ""])), suite.file));
            console.log(chalk_1.default(templateObject_23 || (templateObject_23 = __makeTemplateObject(["  [Groups]: ", " pass, ", " total"], ["  [Groups]: ", " pass, ", " total"])), suite.testGroups.filter(function (e) { return e.pass; }).length.toString(), suite.testGroups.length.toString()));
            console.log(chalk_1.default(templateObject_24 || (templateObject_24 = __makeTemplateObject(["  [Result]: ", ""], ["  [Result]: ", ""])), result));
            console.log(chalk_1.default(templateObject_25 || (templateObject_25 = __makeTemplateObject([" [Summary]: ", " pass, ", " fail, ", " total"], [" [Summary]: ", " pass, ", " fail, ", " total"])), successCount.toString(), (count - successCount).toString(), count.toString()));
            console.log(chalk_1.default(templateObject_26 || (templateObject_26 = __makeTemplateObject(["    [Time]: ", "ms"], ["    [Time]: ", "ms"])), suite.time.toString()));
            console.log("");
        };
        DefaultTestReporter.prototype.onTodo = function (_group, todo) {
            console.log(chalk_1.default(templateObject_27 || (templateObject_27 = __makeTemplateObject(["    {yellow [Todo]:} ", ""], ["    {yellow [Todo]:} ", ""])), todo));
        };
        /**
         * A custom logger function for the default reporter that writes the log values using `console.log()`
         *
         * @param {LogValue} logValue - A value to be logged to the console
         */
        DefaultTestReporter.prototype.onLog = function (logValue) {
            // create string representations of the pointer
            var pointer = logValue.pointer.toString();
            var hexPointer = logValue.pointer.toString(16);
            // log the log message
            if (logValue.pointer > 0) {
                console.log(chalk_1.default(templateObject_28 || (templateObject_28 = __makeTemplateObject(["     {yellow [Log]:} Reference at address [", "] [hex: 0x", "] ", ""], ["     {yellow [Log]:} Reference at address [", "] [hex: 0x", "] ", ""])), pointer, hexPointer, logValue.message));
            }
            else {
                console.log(chalk_1.default(templateObject_29 || (templateObject_29 = __makeTemplateObject(["     {yellow [Log]:} ", ""], ["     {yellow [Log]:} ", ""])), logValue.message));
            }
            // if there are bytes to show, create a logging representation of the bytes
            if (logValue.bytes.length > 0) {
                var value = createReferenceString(logValue.bytes, logValue.pointer, logValue.offset);
                console.log(chalk_1.default(templateObject_30 || (templateObject_30 = __makeTemplateObject(["            {blueBright ", "}"], ["            {blueBright ", "}"])), value.split("\n").join("\n            ")));
            }
            console.log(chalk_1.default(templateObject_31 || (templateObject_31 = __makeTemplateObject(["        {yellow ", "}\n"], ["        {yellow ", "}\\n"])), logValue.stack.split("\n").join("\n        ")));
        };
        return DefaultTestReporter;
    }(TestReporter_1.TestReporter));
    exports.DefaultTestReporter = DefaultTestReporter;
    var templateObject_1, templateObject_2, templateObject_3, templateObject_4, templateObject_5, templateObject_6, templateObject_7, templateObject_8, templateObject_9, templateObject_10, templateObject_11, templateObject_12, templateObject_13, templateObject_14, templateObject_15, templateObject_16, templateObject_17, templateObject_18, templateObject_19, templateObject_20, templateObject_21, templateObject_22, templateObject_23, templateObject_24, templateObject_25, templateObject_26, templateObject_27, templateObject_28, templateObject_29, templateObject_30, templateObject_31;
});
define("util/timeDifference", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.timeDifference = function (end, start) { return Math.round((end - start) * 1000) / 1000; };
});
define("test/RunContext", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    /**
     * This class is a test runner helper class that contains a set of useful properties
     * to help reduce run function size.
     */
    var RunContext = /** @class */ (function () {
        function RunContext(wasm, reporter) {
            this.wasm = wasm;
            this.reporter = reporter;
            this.start = 0;
            this.end = 0;
            this.groupstart = 0;
            this.groupend = 0;
            this.teststart = 0;
            this.testend = 0;
            this.passed = true;
            this.endGroup = false;
        }
        return RunContext;
    }());
    exports.RunContext = RunContext;
});
define("util/IPerformanceConfiguration", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    function createDefaultPerformanceConfiguration() {
        return {
            /** Enable performance statistics gathering. */
            enabled: false,
            /** Set the maximum number of samples to run for each test. */
            maxSamples: 10000,
            /** Set the maximum test run time in milliseconds. */
            maxTestRunTime: 2000,
            /** Set the number of decimal places to round to. */
            roundDecimalPlaces: 3,
            /** Report the median time in the default reporter. */
            reportMedian: true,
            /** Report the average time in milliseconds. */
            reportAverage: true,
            /** Report the standard deviation. */
            reportStandardDeviation: false,
            /** Report the maximum run time in milliseconds. */
            reportMax: false,
            /** Report the minimum run time in milliseconds. */
            reportMin: false,
            /** Report the variance/ */
            reportVariance: false,
        };
    }
    exports.createDefaultPerformanceConfiguration = createDefaultPerformanceConfiguration;
});
define("util/IAspectExports", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
});
define("test/IWarning", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
});
define("test/TestContext", ["require", "exports", "test/TestGroup", "util/LogValue", "util/ActualValue", "test/TestResult", "reporter/DefaultTestReporter", "perf_hooks", "util/timeDifference", "test/RunContext", "util/IPerformanceConfiguration"], function (require, exports, TestGroup_1, LogValue_2, ActualValue_1, TestResult_1, DefaultTestReporter_1, perf_hooks_1, timeDifference_1, RunContext_1, IPerformanceConfiguration_1) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    var wasmFilter = function (input) { return /wasm-function/i.test(input); };
    ;
    var TestContext = /** @class */ (function () {
        function TestContext(reporter, file, performanceConfiguration) {
            if (reporter === void 0) { reporter = new DefaultTestReporter_1.DefaultTestReporter(); }
            if (file === void 0) { file = ""; }
            if (performanceConfiguration === void 0) { performanceConfiguration = IPerformanceConfiguration_1.createDefaultPerformanceConfiguration(); }
            this.reporter = reporter;
            this.file = file;
            this.performanceConfiguration = performanceConfiguration;
            this.groupStack = [new TestGroup_1.TestGroup()];
            this.testGroups = [];
            this.logTarget = this.groupStack[0];
            this.wasm = null;
            // test state machine values
            this.stack = "";
            this.message = "";
            this.actual = null;
            this.expected = null;
            this.time = 0;
            this.pass = true;
            /**
             * This value is used to detect if an `expect()` function call was used outside of a test
             * function. If a reportExpected or reportActual function is called before the `context.run()`
             * method is called, it should prevent the `run()` method from running the tests and report a
             * failure.
             */
            this.ready = false;
            this.errors = [];
            this.resetPerformanceValues();
        }
        /**
         * Run the tests on the wasm module.
         */
        TestContext.prototype.run = function (wasm) {
            if (this.errors.length > 0)
                return;
            this.ready = true;
            this.wasm = wasm;
            var runContext = new RunContext_1.RunContext(wasm, this.reporter);
            // start the test suite
            this.reporter.onStart(this);
            runContext.start = perf_hooks_1.performance.now();
            testgroup: for (var _i = 0, _a = this.testGroups; _i < _a.length; _i++) {
                var group = _a[_i];
                this.runGroup(runContext, group);
            }
            runContext.end = perf_hooks_1.performance.now();
            this.time = timeDifference_1.timeDifference(runContext.end, runContext.start);
            this.pass = runContext.passed;
            this.reporter.onFinish(this);
        };
        TestContext.prototype.runGroup = function (runContext, group) {
            var _this = this;
            // get the group's name
            var groupName = group.describePointers
                .map(function (pointer) { return _this.wasm.getString(pointer); })
                .join(" ");
            group.name = groupName;
            runContext.endGroup = false;
            for (var _i = 0, _a = group.todoPointers; _i < _a.length; _i++) {
                var todoPointer = _a[_i];
                var todo = this.wasm.getString(todoPointer);
                group.todos.push(todo);
                this.reporter.onTodo(group, todo);
            }
            runContext.groupstart = perf_hooks_1.performance.now();
            // set the log target
            this.logTarget = group;
            // for each beforeAllCallback
            this.runBeforeAll(runContext, group);
            // report the group as started, and log all the beforeAll logs outside the describe block
            this.reporter.onGroupStart(group);
            if (runContext.endGroup)
                return;
            for (var i = 0; i < group.testFunctionPointers.length; i++) {
                var result = this.runTest(runContext, group, i);
                if (runContext.endGroup)
                    return;
                this.reporter.onTestFinish(group, result);
                this.logTarget = group;
            }
            // for each afterAllCallback
            this.runAfterAll(runContext, group);
            if (runContext.endGroup)
                return;
            // finish the group
            runContext.groupend = perf_hooks_1.performance.now();
            group.time = timeDifference_1.timeDifference(runContext.groupend, runContext.groupstart);
            group.reason = "Test suite " + groupName + " passed successfully.";
            this.reporter.onGroupFinish(group);
        };
        /**
         * Run a given test.
         *
         * @param {RunContext} runContext - The current run context.
         * @param {TestGroup} group - The current run group.
         * @param {number} testIndex - The current test index.
         */
        TestContext.prototype.runTest = function (runContext, group, testIndex) {
            // create the test result
            var result = new TestResult_1.TestResult();
            var performanceEnabled = group.performanceEnabled[testIndex];
            group.tests.push(result);
            // set the log target
            this.logTarget = result;
            // initialize the test name
            result.name = this.wasm.getString(group.testNamePointers[testIndex]);
            this.reporter.onTestStart(group, result);
            result.start = perf_hooks_1.performance.now();
            // If performance is enabled, use the performance values, otherwise, just run once.
            if (performanceEnabled) {
                var runCount = 0;
                result.performance = true;
                // collect performance variables
                var reportAverage = group.reportAverage[testIndex];
                var reportMax = group.reportMax[testIndex];
                var reportMedian = group.reportMedian[testIndex];
                var reportMin = group.reportMin[testIndex];
                var reportVariance = group.reportVariance[testIndex];
                var reportStandardDeviation = group.reportStandardDeviation[testIndex];
                // sample collection configuration
                var maxSamplesValue = group.maxSamples[testIndex];
                var maxTestRuntimeValue = group.maxTestRuntime[testIndex];
                var decimalPlacesValue = group.roundDecimalPlaces[testIndex];
                // calculate effective values
                var maxSamples = !isFinite(maxSamplesValue)
                    ? 10000 /* MaxSamples */
                    : Math.min(maxSamplesValue, 10000 /* MaxSamples */);
                var maxTestRuntime = !isFinite(maxTestRuntimeValue)
                    ? 5000 /* MaxTestRuntime */
                    : Math.min(maxTestRuntimeValue, 5000 /* MaxTestRuntime */);
                var decimalPlaces = !isFinite(decimalPlacesValue)
                    ? 3
                    : Math.max(decimalPlacesValue, 0 /* MinimumDecimalPlaces */);
                result.decimalPlaces = Math.round(decimalPlaces); // could be a float number
                var testStartTime = perf_hooks_1.performance.now();
                var currentTestRunTime = 0;
                // run the test loop
                while (true) { // always run at least once
                    this.runBeforeEach(runContext, group, result);
                    /**
                     * Especially because the performance functions are run repeatedly, if an error occurs, assume the
                     * worst and skip the test group. These functions definitely are assumed to be safe by the test context.
                     */
                    if (runContext.endGroup)
                        return;
                    this.runTestCall(runContext, group, result, testIndex);
                    this.runAfterEach(runContext, group, result);
                    if (runContext.endGroup)
                        return; // check to see if the afterEach functions errored (see above)
                    currentTestRunTime = perf_hooks_1.performance.now() - testStartTime; // calculate how long the current test has run
                    runCount += 1; // increase the run count
                    if (runCount >= maxSamples)
                        break; // if we have reached the max sample count
                    if (currentTestRunTime >= maxTestRuntime)
                        break; // weve collected enough samples and the test is over
                }
                if (reportAverage)
                    result.calculateAverage();
                if (reportMax)
                    result.calculateMax();
                if (reportMedian)
                    result.calculateMedian();
                if (reportMin)
                    result.calculateMin();
                if (reportVariance)
                    result.calculateVariance();
                if (reportStandardDeviation)
                    result.calculateStandardDeviation();
            }
            else {
                this.runBeforeEach(runContext, group, result);
                if (runContext.endGroup)
                    return;
                this.runTestCall(runContext, group, result, testIndex);
                this.runAfterEach(runContext, group, result);
                if (runContext.endGroup)
                    return;
            }
            result.end = perf_hooks_1.performance.now();
            result.runTime = result.start - result.end;
            return result;
        };
        /**
         * Run the current test once and collect statistics.
         *
         * @param {RunContext} runContext - The current run context.
         * @param {TestGroup} group - The current test group.
         * @param {TestResult} result - The current test result.
         * @param {number} testIndex - The current test index.
         */
        TestContext.prototype.runTestCall = function (runContext, group, result, testIndex) {
            var testFunctionCallback = group.testFunctionPointers[testIndex];
            var start = perf_hooks_1.performance.now();
            var testCallResult = this.tryCall(testFunctionCallback);
            var end = perf_hooks_1.performance.now();
            var throws = group.testThrows[testIndex];
            runContext.testend = perf_hooks_1.performance.now();
            result.times.push(timeDifference_1.timeDifference(end, start));
            result.pass = throws
                ? (testCallResult === 0)
                : (testCallResult === 1);
            result.negated = throws;
            if (!result.pass) {
                group.pass = false;
                // if it throws...
                if (throws) {
                    // only set the message
                    result.message = this.wasm.getString(group.testMessagePointers[testIndex]);
                }
                else {
                    // set the message, the actual, expected, and stack values
                    result.message = this.message;
                    result.actual = this.actual;
                    result.expected = this.expected;
                    result.stack = this.stack;
                }
            }
        };
        /**
         * Run the afterEach callbacks before running the test.
         *
         * @param {RunContext} runContext - The current run context.
         * @param {TestGroup} group - The current test group.
         * @param {TestResult} result - The current test result.
         */
        TestContext.prototype.runAfterEach = function (runContext, group, result) {
            // for each afterEach callback function pointer
            for (var _i = 0, _a = group.afterEachPointers; _i < _a.length; _i++) {
                var afterEachCallback = _a[_i];
                var afterEachResult = this.tryCall(afterEachCallback);
                // if afterEach fails
                if (afterEachResult === 0) {
                    runContext.testend = perf_hooks_1.performance.now();
                    runContext.groupend = perf_hooks_1.performance.now();
                    group.pass = false;
                    group.reason = group.reason = "Test suite " + group.name + " failed in afterEach callback.";
                    result.pass = false;
                    group.time = timeDifference_1.timeDifference(runContext.groupend, runContext.groupstart);
                    this.reporter.onTestFinish(group, result);
                    this.reporter.onGroupFinish(group);
                    runContext.endGroup = true;
                    return;
                }
            }
        };
        /**
         * Run the beforeEach callbacks before running the test.
         *
         * @param {RunContext} runContext - The current run context.
         * @param {TestGroup} group - The current test group.
         * @param {TestResult} result - The current test result.
         */
        TestContext.prototype.runBeforeEach = function (runContext, group, result) {
            // for each beforeEach callback function pointer
            for (var _i = 0, _a = group.beforeEachPointers; _i < _a.length; _i++) {
                var beforeEachCallback = _a[_i];
                var beforeEachResult = this.tryCall(beforeEachCallback);
                // if beforeEach fails
                if (beforeEachResult === 0) {
                    runContext.testend = perf_hooks_1.performance.now();
                    runContext.groupend = perf_hooks_1.performance.now();
                    group.pass = false;
                    group.reason = group.reason = "Test suite " + group.name + " failed in beforeEach callback.";
                    result.pass = false;
                    group.time = timeDifference_1.timeDifference(runContext.groupend, runContext.groupstart);
                    this.reporter.onTestFinish(group, result);
                    this.reporter.onGroupFinish(group);
                    runContext.endGroup = true;
                    return;
                }
            }
        };
        /**
         * Run the afterAll callbacks with the given runContext and group.
         *
         * @param {RunContext} runContext - The current run context.
         * @param {TestGroup} group - The current test group.
         */
        TestContext.prototype.runAfterAll = function (runContext, group) {
            for (var _i = 0, _a = group.afterAllPointers; _i < _a.length; _i++) {
                var afterAllCallback = _a[_i];
                // call each afterAll callback
                var afterAllResult = this.tryCall(afterAllCallback);
                // if the test fails
                if (afterAllResult === 0) {
                    runContext.groupend = perf_hooks_1.performance.now();
                    group.pass = false;
                    group.reason = "Test suite " + group.name + " failed in afterAll callback.";
                    runContext.passed = false;
                    group.time = timeDifference_1.timeDifference(runContext.groupend, runContext.groupstart);
                    this.reporter.onGroupFinish(group);
                    runContext.endGroup = true;
                    return;
                }
            }
        };
        /**
         * Run the beforeAll callbacks with the given runContext and group.
         *
         * @param {RunContext} runContext - The current run context.
         * @param {TestGroup} group - The current test group.
         */
        TestContext.prototype.runBeforeAll = function (runContext, group) {
            for (var _i = 0, _a = group.beforeAllPointers; _i < _a.length; _i++) {
                var beforeAllCallback = _a[_i];
                // call each beforeAll callback
                var beforeAllResult = this.tryCall(beforeAllCallback);
                // if the test fails
                if (beforeAllResult === 0) {
                    runContext.groupend = perf_hooks_1.performance.now();
                    group.pass = false;
                    group.reason = "Test suite " + group.name + " failed in beforeAll callback.";
                    runContext.passed = false;
                    group.time = timeDifference_1.timeDifference(runContext.groupend, runContext.groupstart);
                    runContext.endGroup = true;
                    return;
                }
            }
        };
        /**
         * This method creates a WebAssembly imports object with all the TestContext functions
         * bound to the TestContext.
         *
         * @param {any[]} imports - Every import item specified.
         */
        TestContext.prototype.createImports = function () {
            var _this = this;
            var imports = [];
            for (var _i = 0; _i < arguments.length; _i++) {
                imports[_i] = arguments[_i];
            }
            var result = Object.assign.apply(Object, [{}].concat(imports, [{
                    __aspect: {
                        clearExpected: this.clearExpected.bind(this),
                        debug: this.debug.bind(this),
                        tryCall: this.tryCall.bind(this),
                        logNull: this.logNull.bind(this),
                        logReference: this.logReference.bind(this),
                        logString: this.logString.bind(this),
                        logValue: this.logValue.bind(this),
                        reportDescribe: this.reportDescribe.bind(this),
                        reportEndDescribe: this.reportEndDescribe.bind(this),
                        reportTest: this.reportTest.bind(this),
                        reportBeforeEach: this.reportBeforeEach.bind(this),
                        reportBeforeAll: this.reportBeforeAll.bind(this),
                        reportAfterEach: this.reportAfterEach.bind(this),
                        reportAfterAll: this.reportAfterAll.bind(this),
                        reportTodo: this.reportTodo.bind(this),
                        reportActualNull: this.reportActualNull.bind(this),
                        reportExpectedNull: this.reportExpectedNull.bind(this),
                        reportActualValue: this.reportActualValue.bind(this),
                        reportExpectedValue: this.reportExpectedValue.bind(this),
                        reportActualReference: this.reportActualReference.bind(this),
                        reportExpectedReference: this.reportExpectedReference.bind(this),
                        reportActualString: this.reportActualString.bind(this),
                        reportExpectedString: this.reportExpectedString.bind(this),
                        reportExpectedTruthy: this.reportExpectedTruthy.bind(this),
                        reportExpectedFalsy: this.reportExpectedFalsy.bind(this),
                        reportExpectedFinite: this.reportExpectedFinite.bind(this),
                        reportNegatedTest: this.reportNegatedTest.bind(this),
                        performanceEnabled: this.performanceEnabled.bind(this),
                        maxSamples: this.maxSamples.bind(this),
                        maxTestRunTime: this.maxTestRunTime.bind(this),
                        roundDecimalPlaces: this.roundDecimalPlaces.bind(this),
                        reportAverage: this.reportAverage.bind(this),
                        reportMedian: this.reportMedian.bind(this),
                        reportStdDev: this.reportStdDev.bind(this),
                        reportMax: this.reportMax.bind(this),
                        reportMin: this.reportMin.bind(this),
                        reportVariance: this.reportVariance.bind(this),
                    },
                }]));
            result.env = result.env || {};
            var previousAbort = (result.env.abort) || (function () { });
            result.env.abort = function () {
                var args = [];
                for (var _i = 0; _i < arguments.length; _i++) {
                    args[_i] = arguments[_i];
                }
                previousAbort.apply(void 0, args);
                // @ts-ignore
                _this.abort.apply(_this, args);
            };
            return result;
        };
        /**
         * This web assembly linked function creates a test group. It's called when the test suite calls
         * the describe("test", callback) function from within AssemblyScript. It receives a pointer to
         * the description of the tests, forks the top level test group, pushes the suiteName to a list,
         * then pushes the forked group to the top of the test context stack.
         *
         * @param {number} suiteNamePointer
         */
        TestContext.prototype.reportDescribe = function (suiteNamePointer) {
            var group = this.groupStack[this.groupStack.length - 1];
            var nextGroup = group.fork();
            nextGroup.describePointers.push(suiteNamePointer);
            this.groupStack.push(nextGroup);
            this.logTarget = nextGroup;
        };
        /**
         * This web assembly linked function finishes a test group. It's called when the test suite calls
         * the describe("test", callback) function from within AssemblyScript. It pops the current
         * test group from the test context stack and pushes it to the final test group list.
         */
        TestContext.prototype.reportEndDescribe = function () {
            var next = this.groupStack.pop();
            /**
             * If a describe finishes first, it happens BEFORE other describes. This means
             * inner describe blocks run at lower priority than outer describe blocks.
             */
            this.testGroups.unshift(next);
            this.logTarget = this.groupStack[this.groupStack.length - 1];
        };
        /**
         * This web assembly linked function sets the group's "beforeEach" callback pointer to
         * the current groupStackItem.
         *
         * @param {number} callbackPointer - The callback that should run before each test.
         */
        TestContext.prototype.reportBeforeEach = function (callbackPointer) {
            var group = this.groupStack[this.groupStack.length - 1];
            ;
            group.beforeEachPointers.push(callbackPointer);
        };
        /**
         * This web assembly linked function adds the group's "beforeAll" callback pointer to
         * the current groupStackItem.
         *
         * @param {number} callbackPointer - The callback that should run before each test in the
         * current context.
         */
        TestContext.prototype.reportBeforeAll = function (callbackPointer) {
            var group = this.groupStack[this.groupStack.length - 1];
            ;
            group.beforeAllPointers.push(callbackPointer);
        };
        /**
         * This web assembly linked function sets the group's "afterEach" callback pointer.
         *
         * @param {number} callbackPointer - The callback that should run before each test group.
         */
        TestContext.prototype.reportAfterEach = function (callbackPointer) {
            var group = this.groupStack[this.groupStack.length - 1];
            ;
            group.afterEachPointers.push(callbackPointer);
        };
        /**
         * This web assembly linked function adds the group's "afterAll" callback pointer to
         * the current groupStackItem.
         *
         * @param {number} callbackPointer - The callback that should run before each test in the
         * current context.
         */
        TestContext.prototype.reportAfterAll = function (callbackPointer) {
            var group = this.groupStack[this.groupStack.length - 1];
            ;
            group.afterAllPointers.push(callbackPointer);
        };
        /**
         * This is a web assembly utility function that wraps a function call in a try catch block to
         * report success or failure.
         *
         * @param {number} pointer - The function pointer to call. It must accept no parameters and return
         * void.
         * @returns {1 | 0} - If the callback was run successfully without error, it returns 1, else it
         * returns 0.
         */
        TestContext.prototype.tryCall = function (pointer) {
            if (pointer === -1)
                return 1;
            try {
                this.wasm.__call(pointer);
            }
            catch (ex) {
                this.stack = this.getErrorStackTrace(ex);
                return 0;
            }
            return 1;
        };
        /**
         * This adds a logged string to the current test.
         *
         * @param {number} pointer - The pointer to the logged string reference.
         */
        TestContext.prototype.logString = function (pointer) {
            var value = new LogValue_2.LogValue();
            var target = this.logTarget;
            value.message = this.wasm.getString(pointer);
            value.offset = 0;
            value.pointer = pointer;
            value.stack = this.getLogStackTrace();
            value.target = target;
            value.value = pointer;
            // push the log value to the logs
            target.logs.push(value);
        };
        /**
         * Log a reference to the reporter.
         *
         * @param {number} referencePointer - The pointer to the reference.
         * @param {number} offset - The offset of the reference.
         */
        TestContext.prototype.logReference = function (referencePointer, offset) {
            var value = new LogValue_2.LogValue();
            var target = this.logTarget;
            value.bytes = Array.from(this.wasm.U8.slice(referencePointer, referencePointer + offset));
            value.message = "Reference Type";
            value.offset = offset;
            value.pointer = referencePointer;
            value.stack = this.getLogStackTrace();
            value.target = target;
            value.value = referencePointer;
            // push the log value to the logs
            target.logs.push(value);
        };
        /**
         * Log a numevalueric value to the reporter.
         *
         * @param {number} value - The value to be logged.
         */
        TestContext.prototype.logValue = function (numericValue) {
            var value = new LogValue_2.LogValue();
            var target = this.logTarget;
            value.stack = this.getLogStackTrace();
            value.message = "Value " + numericValue.toString();
            value.value = numericValue;
            value.target = target;
            // push the log value to the logs
            target.logs.push(value);
        };
        /**
         * Log a null value to the reporter.
         */
        TestContext.prototype.logNull = function () {
            // create a new log value
            var value = new LogValue_2.LogValue();
            var target = this.logTarget;
            // collect log metadata
            value.stack = this.getLogStackTrace();
            value.message = "null";
            value.target = target;
            // push the log value to the logs
            target.logs.push(value);
        };
        /**
         * Gets a log stack trace.
         */
        TestContext.prototype.getLogStackTrace = function () {
            try {
                throw new Error("Get stack trace.");
            }
            catch (ex) {
                return ex.stack.toString()
                    .split("\n")
                    .slice(1)
                    .filter(wasmFilter)
                    .join("\n");
            }
        };
        /**
         * Gets an error stack trace.
         */
        TestContext.prototype.getErrorStackTrace = function (ex) {
            var stackItems = ex.stack.toString().split("\n");
            return [stackItems[0]].concat(stackItems.slice(1).filter(wasmFilter)).join("\n");
        };
        /**
         * This is called to stop the debugger.  e.g. `node --inspect-brk asp`.
         */
        TestContext.prototype.debug = function () { debugger; };
        /**
         * This web assembly linked function creates a test from the callback and the testNamePointer in
         * the current group. It assumes that the group has already been created with the describe
         * function. It is called when `it("description", callback)` or `test("description", callback)`
         * is called.
         *
         * @param {number} testNamePointer - The test's name pointer.
         * @param {number} callback - The test's function.
         */
        TestContext.prototype.reportTest = function (testNamePointer, callback) {
            var group = this.groupStack[this.groupStack.length - 1];
            group.testFunctionPointers.push(callback);
            group.testNamePointers.push(testNamePointer);
            group.testMessagePointers.push(-1);
            group.testThrows.push(false);
            group.performanceEnabled.push(this.performanceEnabledValue);
            group.maxSamples.push(this.maxSamplesValue);
            group.maxTestRuntime.push(this.maxTestRunTimeValue);
            group.roundDecimalPlaces.push(this.roundDecimalPlacesValue);
            group.reportAverage.push(this.recordAverageValue);
            group.reportMedian.push(this.recordMedianValue);
            group.reportStandardDeviation.push(this.recordStdDevValue);
            group.reportMax.push(this.recordMaxValue);
            group.reportMin.push(this.recordMinValue);
            group.reportVariance.push(this.recordVariance);
            this.resetPerformanceValues();
        };
        /**
         * This web assembly linked function is responsible for reporting tests that are expected
         * to fail. This is useful for verifying that specific application states will throw.
         *
         * @param {number} testNamePointer - The test's name pointer.
         * @param {number} callback - The test's function.
         * @param {number} message - The message associated with this test if it does not throw.
         */
        TestContext.prototype.reportNegatedTest = function (testNamePointer, callback, message) {
            var group = this.groupStack[this.groupStack.length - 1];
            group.testFunctionPointers.push(callback);
            group.testNamePointers.push(testNamePointer);
            group.testMessagePointers.push(message);
            group.testThrows.push(true);
            group.performanceEnabled.push(this.performanceEnabledValue);
            group.maxSamples.push(this.maxSamplesValue);
            group.maxTestRuntime.push(this.maxTestRunTimeValue);
            group.roundDecimalPlaces.push(this.roundDecimalPlacesValue);
            group.reportAverage.push(this.recordAverageValue);
            group.reportMedian.push(this.recordMedianValue);
            group.reportStandardDeviation.push(this.recordStdDevValue);
            group.reportMax.push(this.recordMaxValue);
            group.reportMin.push(this.recordMinValue);
            group.reportVariance.push(this.recordVariance);
            this.resetPerformanceValues();
        };
        /**
         * This function reports a single "todo" item in a test suite.
         *
         * @param {number} todoPointer - The todo description string pointer.
         */
        TestContext.prototype.reportTodo = function (todoPointer) {
            var group = this.groupStack[this.groupStack.length - 1];
            group.todoPointers.push(todoPointer);
        };
        /**
          * This function is called after each expectation if the expectation passes. This prevents other
          * unreachable() conditions that throw errors to report actual and expected values too.
          */
        TestContext.prototype.clearExpected = function () {
            this.expected = null;
            this.actual = null;
            this.stack = "";
        };
        /**
         * This function reports an actual null value.
         */
        TestContext.prototype.reportActualNull = function () {
            if (!this.ready) {
                this.reportInvalidExpectCall();
                return;
            }
            var value = new ActualValue_1.ActualValue();
            value.message = "null";
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.value = null;
            this.actual = value;
        };
        /**
         * This function reports an expected null value.
         *
         * @param {1 | 0} negated - An indicator if the expectation is negated.
         */
        TestContext.prototype.reportExpectedNull = function (negated) {
            var value = new ActualValue_1.ActualValue();
            value.message = "null";
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.negated = negated === 1;
            value.value = null;
            this.expected = value;
        };
        /**
         * This function reports an actual numeric value.
         *
         * @param {number} numericValue - The value to be expected.
         */
        TestContext.prototype.reportActualValue = function (numericValue) {
            if (!this.ready) {
                this.reportInvalidExpectCall();
                return;
            }
            var value = new ActualValue_1.ActualValue();
            value.message = numericValue.toString();
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.value = numericValue;
            this.actual = value;
        };
        /**
         * This function reports an expected numeric value.
         *
         * @param {number} numericValue - The value to be expected
         * @param {1 | 0} negated - An indicator if the expectation is negated.
         */
        TestContext.prototype.reportExpectedValue = function (numericValue, negated) {
            var value = new ActualValue_1.ActualValue();
            value.message = numericValue.toString();
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.negated = negated === 1;
            value.value = numericValue;
            this.expected = value;
        };
        /**
         * This function reports an actual reference value.
         *
         * @param {number} referencePointer - The actual reference pointer.
         * @param {number} offset - The size of the reference in bytes.
         */
        TestContext.prototype.reportActualReference = function (referencePointer, offset) {
            if (!this.ready) {
                this.reportInvalidExpectCall();
                return;
            }
            var value = new ActualValue_1.ActualValue();
            value.message = "Reference Value";
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.pointer = referencePointer;
            value.offset = offset;
            value.bytes = Array.from(this.wasm.U8.slice(referencePointer, referencePointer + offset));
            value.value = referencePointer;
            this.actual = value;
        };
        /**
         * This function reports an expected reference value.
         *
         * @param {number} referencePointer - The expected reference pointer.
         * @param {number} offset - The size of the reference in bytes.
         * @param {1 | 0} negated - An indicator if the expectation is negated.
         */
        TestContext.prototype.reportExpectedReference = function (referencePointer, offset, negated) {
            var value = new ActualValue_1.ActualValue();
            value.message = "Reference Value";
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.pointer = referencePointer;
            value.offset = offset;
            value.bytes = Array.from(this.wasm.U8.slice(referencePointer, referencePointer + offset));
            value.negated = negated === 1;
            value.value = referencePointer;
            this.expected = value;
        };
        /**
         * This function reports an expected truthy value.
         *
         * @param {1 | 0} negated - An indicator if the expectation is negated.
         */
        TestContext.prototype.reportExpectedTruthy = function (negated) {
            var value = new ActualValue_1.ActualValue();
            value.message = "Truthy Value";
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.negated = negated === 1;
            this.expected = value;
        };
        /**
         * This function reports an expected falsy value.
         *
         * @param {1 | 0} negated - An indicator if the expectation is negated.
         */
        TestContext.prototype.reportExpectedFalsy = function (negated) {
            var value = new ActualValue_1.ActualValue();
            value.message = "Falsy Value";
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.negated = negated === 1;
            this.expected = value;
        };
        /**
         * This function reports an expected finite value.
         *
         * @param {1 | 0} negated - An indicator if the expectation is negated.
         */
        TestContext.prototype.reportExpectedFinite = function (negated) {
            var value = new ActualValue_1.ActualValue();
            value.message = "Finite Value";
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.negated = negated === 1;
            this.expected = value;
        };
        /**
         * This function reports an actual string value.
         *
         * @param {number} stringPointer - A pointer that points to the actual string.
         */
        TestContext.prototype.reportActualString = function (stringPointer) {
            if (!this.ready) {
                this.reportInvalidExpectCall();
                return;
            }
            var value = new ActualValue_1.ActualValue();
            value.message = this.wasm.getString(stringPointer);
            value.pointer = stringPointer;
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.value = stringPointer;
            this.actual = value;
        };
        /**
         * This function reports an expected string value.
         *
         * @param {number} stringPointer - A pointer that points to the expected string.
         * @param {1 | 0} negated - An indicator if the expectation is negated.
         */
        TestContext.prototype.reportExpectedString = function (stringPointer, negated) {
            var value = new ActualValue_1.ActualValue();
            value.message = this.wasm.getString(stringPointer);
            value.pointer = stringPointer;
            value.stack = this.getLogStackTrace();
            value.target = this.logTarget;
            value.negated = negated === 1;
            value.value = stringPointer;
            this.expected = value;
        };
        /**
         * This function overrides the provided AssemblyScript `env.abort()` function to catch abort
         * reasons.
         *
         * @param {number} reasonPointer - This points to the message value that causes the expectation to
         * fail.
         * @param {number} _fileNamePointer - The file name that reported the error. (Ignored)
         * @param {number} _line - The line that reported the error. (Ignored)
         * @param {number} _col - The column that reported the error. (Ignored)
         */
        TestContext.prototype.abort = function (reasonPointer, _fileNamePointer, _line, _col) {
            this.message = this.wasm.getString(reasonPointer);
        };
        /**
         * Reset all the performance values to the configured values.
         */
        TestContext.prototype.resetPerformanceValues = function () {
            this.performanceEnabledValue = this.performanceConfiguration.enabled;
            this.maxSamplesValue = this.performanceConfiguration.maxSamples;
            this.maxTestRunTimeValue = this.performanceConfiguration.maxTestRunTime;
            this.roundDecimalPlacesValue = this.performanceConfiguration.roundDecimalPlaces;
            this.recordAverageValue = this.performanceConfiguration.reportAverage;
            this.recordMedianValue = this.performanceConfiguration.reportMedian;
            this.recordStdDevValue = this.performanceConfiguration.reportStandardDeviation;
            this.recordMaxValue = this.performanceConfiguration.reportMax;
            this.recordMinValue = this.performanceConfiguration.reportMin;
            this.recordVariance = this.performanceConfiguration.reportVariance;
        };
        /**
         * This web assembly linked function modifies the state machine to enable
         * performance for the following test.
         *
         * @param {1 | 0} value - A value indicating if performance should be enabled.
         */
        TestContext.prototype.performanceEnabled = function (value) {
            this.performanceEnabledValue = value === 1;
        };
        /**
         * This web assembly linked function modifies the state machine to set the maximum number of
         * samples for the following test.
         *
         * @param {number} value - The maximum number of samples to collect for the following test.
         */
        TestContext.prototype.maxSamples = function (value) {
            this.maxSamplesValue = value;
        };
        /**
         * This web assembly linked function modifies the state machine to set the maximum amount of
         * time to run the following test in milliseconds
         *
         * @param {number} value - The maximum number of milliseconds to run the following test.
         */
        TestContext.prototype.maxTestRunTime = function (value) {
            this.maxTestRunTimeValue = value;
        };
        /**
         * This web assembly linked function modifies the state machine to set the number of decimal places
         * to round all the statistics to.
         *
         * @param {number} value - The number of decimal places to round to.
         */
        TestContext.prototype.roundDecimalPlaces = function (value) {
            this.roundDecimalPlacesValue = value;
        };
        /**
         * This web assembly linked function modifies the state machine to cause the next test to report
         * an average run time.
         *
         * @param {1 | 0} value - A boolean indicating if the average should be reported.
         */
        TestContext.prototype.reportAverage = function (value) {
            this.recordAverageValue = value === 1;
        };
        /**
         * This web assembly linked function modifies the state machine to cause the next test to report
         * an median run time.
         *
         * @param {1 | 0} value - A boolean indicating if the median should be reported.
         */
        TestContext.prototype.reportMedian = function (value) {
            this.recordMedianValue = value === 1;
        };
        /**
         * This web assembly linked function modifies the state machine to cause the next test to report
         * a standard deviation calculation on the run times.
         *
         * @param {1 | 0} value - A boolean indicating if the standard deviation should be reported.
         */
        TestContext.prototype.reportStdDev = function (value) {
            this.recordStdDevValue = value === 1;
        };
        /**
         * This web assembly linked function modifies the state machine to cause the next test to report
         * the maximum run time for this test.
         *
         * @param {1 | 0} value - A boolean indicating if the max should be reported.
         */
        TestContext.prototype.reportMax = function (value) {
            this.recordMaxValue = value === 1;
        };
        /**
         * This web assembly linked function modifies the state machine to cause the next test to report
         * the minimum run time for this test.
         *
         * @param {1 | 0} value - A boolean indicating if the min should be reported.
         */
        TestContext.prototype.reportMin = function (value) {
            this.recordMinValue = value === 1;
        };
        /**
         * This web assembly linked function modifies the state machine to cause the next test to report
         * the variance of the run times for this test.
         *
         * @param {1 | 0} value - A boolean indicating if the min should be reported.
         */
        TestContext.prototype.reportVariance = function (value) {
            this.recordVariance = value === 1;
        };
        /**
         * This method reports to the TestContext that an expect function call was used outside of the
         * intended test functions.
         */
        TestContext.prototype.reportInvalidExpectCall = function () {
            this.errors.push({
                type: "InvalidExpectCall",
                message: "An expect() function call was used outside of a test function in " + this.file + ".",
                stackTrace: this.getLogStackTrace(),
            });
        };
        return TestContext;
    }());
    exports.TestContext = TestContext;
});
define("reporter/EmptyReporter", ["require", "exports", "test/TestReporter"], function (require, exports, TestReporter_2) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    var EmptyReporter = /** @class */ (function (_super) {
        __extends(EmptyReporter, _super);
        function EmptyReporter() {
            return _super !== null && _super.apply(this, arguments) || this;
        }
        EmptyReporter.prototype.onFinish = function () { };
        EmptyReporter.prototype.onGroupFinish = function () { };
        EmptyReporter.prototype.onGroupStart = function () { };
        EmptyReporter.prototype.onStart = function () { };
        EmptyReporter.prototype.onTestFinish = function () { };
        EmptyReporter.prototype.onTestStart = function () { };
        EmptyReporter.prototype.onTodo = function () { };
        return EmptyReporter;
    }(TestReporter_2.TestReporter));
    exports.EmptyReporter = EmptyReporter;
});
define("reporter/SummaryTestReporter", ["require", "exports", "test/TestReporter", "chalk"], function (require, exports, TestReporter_3, chalk_2) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    chalk_2 = __importDefault(chalk_2);
    var SummaryTestReporter = /** @class */ (function (_super) {
        __extends(SummaryTestReporter, _super);
        function SummaryTestReporter() {
            return _super.call(this) || this;
        }
        SummaryTestReporter.prototype.onStart = function () { };
        SummaryTestReporter.prototype.onGroupStart = function () { };
        SummaryTestReporter.prototype.onGroupFinish = function () { };
        SummaryTestReporter.prototype.onTestStart = function () { };
        SummaryTestReporter.prototype.onTestFinish = function () { };
        SummaryTestReporter.prototype.onTodo = function () { };
        SummaryTestReporter.prototype.onFinish = function (suite) {
            var _a, _b;
            var tests = (_a = []).concat.apply(_a, suite.testGroups.map(function (e) { return e.tests; }));
            var todos = (_b = []).concat.apply(_b, suite.testGroups.map(function (e) { return e.todos; })).length;
            var total = tests.length;
            var pass = tests.reduce(function (left, right) { return right.pass ? left + 1 : left; }, 0);
            if (pass === total) {
                console.log(chalk_2.default(templateObject_32 || (templateObject_32 = __makeTemplateObject(["{green.bold \u2714 ", "} Pass: ", " / ", " Todo: ", " Time: ", "ms"], ["{green.bold \u2714 ", "} Pass: ", " / ", " Todo: ", " Time: ", "ms"])), suite.file, pass.toString(), total.toString(), todos.toString(), suite.time.toString()));
            }
            else {
                console.log(chalk_2.default(templateObject_33 || (templateObject_33 = __makeTemplateObject(["{red.bold \u274C ", "} Pass: ", " / ", " Todo: ", " Time: ", "ms"], ["{red.bold \u274C ", "} Pass: ", " / ", " Todo: ", " Time: ", "ms"])), suite.file, pass.toString(), total.toString(), todos.toString(), suite.time.toString()));
                for (var _i = 0, _c = suite.testGroups; _i < _c.length; _i++) {
                    var group = _c[_i];
                    if (group.pass)
                        continue;
                    console.log(chalk_2.default(templateObject_34 || (templateObject_34 = __makeTemplateObject(["  ", ""], ["  ", ""])), group.name));
                    inner: for (var _d = 0, _e = group.tests; _d < _e.length; _d++) {
                        var test_1 = _e[_d];
                        if (test_1.pass)
                            continue inner;
                        console.log(chalk_2.default(templateObject_35 || (templateObject_35 = __makeTemplateObject(["    {red.bold \u274C ", "} - ", ""], ["    {red.bold \u274C ", "} - ", ""])), test_1.name, test_1.message));
                        if (test_1.expected !== null)
                            console.log(chalk_2.default(templateObject_36 || (templateObject_36 = __makeTemplateObject(["      {green.bold [Expected]:} ", ""], ["      {green.bold [Expected]:} ", ""])), test_1.expected.message));
                        if (test_1.actual !== null)
                            console.log(chalk_2.default(templateObject_37 || (templateObject_37 = __makeTemplateObject(["      {red.bold [Actual]  :} ", ""], ["      {red.bold [Actual]  :} ", ""])), test_1.actual.message));
                    }
                }
            }
        };
        return SummaryTestReporter;
    }(TestReporter_3.TestReporter));
    exports.SummaryTestReporter = SummaryTestReporter;
    var templateObject_32, templateObject_33, templateObject_34, templateObject_35, templateObject_36, templateObject_37;
});
define("util/IConfiguration", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
});
define("cli", ["require", "exports", "chalk", "path", "glob", "yargs-parser", "assemblyscript/cli/asc", "test/TestContext", "fs", "assemblyscript/lib/loader", "reporter/DefaultTestReporter", "perf_hooks", "util/timeDifference", "util/IPerformanceConfiguration", "reporter/EmptyReporter", "reporter/SummaryTestReporter"], function (require, exports, chalk_3, path_1, glob_1, yargs_parser_1, asc_1, TestContext_1, fs_1, loader_1, DefaultTestReporter_2, perf_hooks_2, timeDifference_2, IPerformanceConfiguration_2, EmptyReporter_1, SummaryTestReporter_1) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    chalk_3 = __importDefault(chalk_3);
    path_1 = __importDefault(path_1);
    glob_1 = __importDefault(glob_1);
    yargs_parser_1 = __importDefault(yargs_parser_1);
    asc_1 = __importDefault(asc_1);
    fs_1 = __importDefault(fs_1);
    var pkg = require("../package.json");
    /**
     * This is the cli entry point and expects an array of arguments from the command line.
     *
     * @param {string[]} args - The arguments from the command line
     */
    function asp(args) {
        // parse the arguments
        var yargs = {
            argv: yargs_parser_1.default(args),
        };
        // Skip ascii art if asked for the version
        if (!(yargs.argv.v || yargs.argv.version)) {
            console.log(chalk_3.default(templateObject_38 || (templateObject_38 = __makeTemplateObject(["{bold.bgWhite.black ", "       ___   _____                       __  \n      /   | / ___/      ____  ___  _____/ /_ \n     / /| | \\__ \\______/ __ \\/ _ \\/ ___/ __/ \n    / ___ |___/ /_____/ /_/ /  __/ /__/ /_   \n   /_/  |_/____/     / .___/\\___/\\___/\\__/   \n                    /_/                      }\n\n  \u26A1AS-pect\u26A1 Test suite runner {bgGreenBright.black [", "]}\n  "], ["{bold.bgWhite.black ",
                "       ___   _____                       __  \n      /   | / ___/      ____  ___  _____/ /_ \n     / /| | \\\\__ \\\\______/ __ \\\\/ _ \\\\/ ___/ __/ \n    / ___ |___/ /_____/ /_/ /  __/ /__/ /_   \n   /_/  |_/____/     / .___/\\\\___/\\\\___/\\\\__/   \n                    /_/                      }\n\n  \u26A1AS-pect\u26A1 Test suite runner {bgGreenBright.black [", "]}\n  "])), "", pkg.version));
        }
        var assemblyFolder = path_1.default.join(process.cwd(), "assembly");
        var testFolder = path_1.default.join(process.cwd(), "assembly", "__tests__");
        var typesFileSource = path_1.default.join(__dirname, "..", "assembly", "__tests__", "as-pect.d.ts");
        var typesFile = path_1.default.join(testFolder, "as-pect.d.ts");
        if (yargs.argv.t || yargs.argv.types) {
            console.log("");
            console.log(chalk_3.default(templateObject_39 || (templateObject_39 = __makeTemplateObject(["[Log] Initializing types."], ["[Log] Initializing types."]))));
            console.log("");
            // Create the assembly folder if it doesn't exist
            if (!fs_1.default.existsSync(assemblyFolder)) {
                console.log(chalk_3.default(templateObject_40 || (templateObject_40 = __makeTemplateObject(["[Log] Creating folder: ./assembly/"], ["[Log] Creating folder: ./assembly/"]))));
                fs_1.default.mkdirSync(assemblyFolder);
            }
            // Create the test folder if it doesn't exist
            if (!fs_1.default.existsSync(testFolder)) {
                console.log(chalk_3.default(templateObject_41 || (templateObject_41 = __makeTemplateObject(["[Log] Creating folder: ./assembly/__tests__/"], ["[Log] Creating folder: ./assembly/__tests__/"]))));
                fs_1.default.mkdirSync(testFolder);
            }
            // Create the types file if it doesn't exist
            if (!fs_1.default.existsSync(typesFile)) {
                console.log(chalk_3.default(templateObject_42 || (templateObject_42 = __makeTemplateObject(["[Log] Creating file: assembly/__tests__/as-pect.d.ts"], ["[Log] Creating file: assembly/__tests__/as-pect.d.ts"]))));
                fs_1.default.createReadStream(typesFileSource, "utf-8")
                    .pipe(fs_1.default.createWriteStream(typesFile, "utf-8"));
            }
        }
        else if (yargs.argv.i || yargs.argv.init) {
            // init script
            console.log("");
            console.log(chalk_3.default(templateObject_43 || (templateObject_43 = __makeTemplateObject(["[Log] Initializing test suite files."], ["[Log] Initializing test suite files."]))));
            console.log("");
            // create the assembly folder if it doesn't exist
            if (!fs_1.default.existsSync(assemblyFolder)) {
                console.log(chalk_3.default(templateObject_44 || (templateObject_44 = __makeTemplateObject(["[Log] Creating folder: ./assembly/"], ["[Log] Creating folder: ./assembly/"]))));
                fs_1.default.mkdirSync(assemblyFolder);
            }
            // Create the test folder if it doesn't exist
            if (!fs_1.default.existsSync(testFolder)) {
                console.log(chalk_3.default(templateObject_45 || (templateObject_45 = __makeTemplateObject(["[Log] Creating folder: ./assembly/__tests__/"], ["[Log] Creating folder: ./assembly/__tests__/"]))));
                fs_1.default.mkdirSync(testFolder);
                // create the example file only if the __tests__ folder does not exist
                var exampleFile = path_1.default.join(testFolder, "example.spec.ts");
                var exampleFileSource = path_1.default.join(__dirname, "..", "init", "example.spec.ts");
                if (!fs_1.default.existsSync(exampleFile)) {
                    console.log(chalk_3.default(templateObject_46 || (templateObject_46 = __makeTemplateObject(["[Log] Creating file: ./assembly/__tests__/example.spec.ts"], ["[Log] Creating file: ./assembly/__tests__/example.spec.ts"]))));
                    fs_1.default.createReadStream(exampleFileSource, "utf-8")
                        .pipe(fs_1.default.createWriteStream(exampleFile, "utf-8"));
                }
            }
            // create the types file if it doesn't exist for typescript tooling users
            if (!fs_1.default.existsSync(typesFile)) {
                console.log(chalk_3.default(templateObject_47 || (templateObject_47 = __makeTemplateObject(["[Log] Creating file: assembly/__tests__/as-pect.d.ts"], ["[Log] Creating file: assembly/__tests__/as-pect.d.ts"]))));
                fs_1.default.createReadStream(typesFileSource, "utf-8")
                    .pipe(fs_1.default.createWriteStream(typesFile, "utf-8"));
            }
            // create the default configuration file
            var configFile = path_1.default.join(process.cwd(), "as-pect.config.js");
            var configFileSource = path_1.default.join(__dirname, "..", "init", "as-pect.config.js");
            if (!fs_1.default.existsSync(configFile)) {
                console.log(chalk_3.default(templateObject_48 || (templateObject_48 = __makeTemplateObject(["[Log] Creating file: as-pect.config.js"], ["[Log] Creating file: as-pect.config.js"]))));
                fs_1.default.createReadStream(configFileSource, "utf-8")
                    .pipe(fs_1.default.createWriteStream(configFile, "utf-8"));
            }
        }
        else if (yargs.argv.v || yargs.argv.version) { // display the version
            console.log(pkg.version);
        }
        else if (yargs.argv.help || yargs.argv.h) { // display the help file
            console.log(chalk_3.default(templateObject_49 || (templateObject_49 = __makeTemplateObject(["\n  {bold.blueBright SYNTAX}\n    {bold.green asp} --init                          Create a test config, an assembly/__tests__ folder and exit.\n    {bold.green asp} -i\n    {bold.green asp} --config=as-pect.config.js      Use a specified configuration\n    {bold.green asp} -c as-pect.config.js\n    {bold.green asp} --version                       View the version.\n    {bold.green asp} -v\n    {bold.green asp} --help                          Show this help screen.\n    {bold.green asp} -h\n    {bold.green asp} --types                         Copy the types file to assembly/__tests__/as-pect.d.ts\n    {bold.green asp} -t\n\n  {bold.blueBright TEST OPTIONS}\n    {bold.green --reporter}                           Define the reporter to be used. {yellow (Default: DefaultTestReporter)}\n      {bold.green --reporter=SummaryTestReporter}     Use the summary reporter.\n      {bold.green --reporter=DefaultTestReporter}     Use the default test reporter.\n      {bold.green --reporter=EmptyReporter}           Use the empty reporter. {yellow (This reporter reports nothing)}\n      {bold.green --reporter=./path/to/reporter.js}   Use the default exported object from this module as the reporter.\n\n    {bold.green --performance}                        Enable performance statistics. {yellow (Default: false)}\n    {bold.green --max-samples=[number]}               Set the maximum number of samples to run for each test. {yellow (Default: 10000 samples)}\n    {bold.green --max-test-run-time=[number]}         Set the maximum test run time in milliseconds. {yellow (Default: 2000ms)}\n    {bold.green --round-decimal-places=[number]}      Set the number of decimal places to round to. {yellow (Default: 3)}\n    {bold.green --report-median(=false)?}             Enable/Disable reporting of the median time. {yellow (Default: true)}\n    {bold.green --report-average(=false)?}            Enable/Disable reporting of the average time. {yellow (Default: true)}\n    {bold.green --report-standard-deviation(=false)?} Enable/Disable reporting of the standard deviation. {yellow (Default: false)}\n    {bold.green --report-max(=false)?}                Enable/Disable reporting of the largest run time. {yellow (Default: false)}\n    {bold.green --report-min(=false)?}                Enable/Disable reporting of the smallest run time. {yellow (Default: false)}\n    {bold.green --report-variance(=false)?}           Enable/Disable reporting of the variance. {yellow (Default: false)}\n  "], ["\n  {bold.blueBright SYNTAX}\n    {bold.green asp} --init                          Create a test config, an assembly/__tests__ folder and exit.\n    {bold.green asp} -i\n    {bold.green asp} --config=as-pect.config.js      Use a specified configuration\n    {bold.green asp} -c as-pect.config.js\n    {bold.green asp} --version                       View the version.\n    {bold.green asp} -v\n    {bold.green asp} --help                          Show this help screen.\n    {bold.green asp} -h\n    {bold.green asp} --types                         Copy the types file to assembly/__tests__/as-pect.d.ts\n    {bold.green asp} -t\n\n  {bold.blueBright TEST OPTIONS}\n    {bold.green --reporter}                           Define the reporter to be used. {yellow (Default: DefaultTestReporter)}\n      {bold.green --reporter=SummaryTestReporter}     Use the summary reporter.\n      {bold.green --reporter=DefaultTestReporter}     Use the default test reporter.\n      {bold.green --reporter=EmptyReporter}           Use the empty reporter. {yellow (This reporter reports nothing)}\n      {bold.green --reporter=./path/to/reporter.js}   Use the default exported object from this module as the reporter.\n\n    {bold.green --performance}                        Enable performance statistics. {yellow (Default: false)}\n    {bold.green --max-samples=[number]}               Set the maximum number of samples to run for each test. {yellow (Default: 10000 samples)}\n    {bold.green --max-test-run-time=[number]}         Set the maximum test run time in milliseconds. {yellow (Default: 2000ms)}\n    {bold.green --round-decimal-places=[number]}      Set the number of decimal places to round to. {yellow (Default: 3)}\n    {bold.green --report-median(=false)?}             Enable/Disable reporting of the median time. {yellow (Default: true)}\n    {bold.green --report-average(=false)?}            Enable/Disable reporting of the average time. {yellow (Default: true)}\n    {bold.green --report-standard-deviation(=false)?} Enable/Disable reporting of the standard deviation. {yellow (Default: false)}\n    {bold.green --report-max(=false)?}                Enable/Disable reporting of the largest run time. {yellow (Default: false)}\n    {bold.green --report-min(=false)?}                Enable/Disable reporting of the smallest run time. {yellow (Default: false)}\n    {bold.green --report-variance(=false)?}           Enable/Disable reporting of the variance. {yellow (Default: false)}\n  "]))));
        }
        else { // run the compiler and test suite
            var start_1 = perf_hooks_2.performance.now();
            // obtain the configuration file
            var configurationPath = path_1.default.resolve(process.cwd(), yargs.argv.c || yargs.argv.config || "./as-pect.config.js");
            console.log(chalk_3.default(templateObject_50 || (templateObject_50 = __makeTemplateObject(["{bgWhite.black [Log]} using configuration ", ""], ["{bgWhite.black [Log]} using configuration ", ""])), configurationPath));
            var configuration_1 = {};
            try {
                configuration_1 = require(configurationPath) || {};
            }
            catch (ex) {
                console.log("");
                console.log(chalk_3.default(templateObject_51 || (templateObject_51 = __makeTemplateObject(["{bgRedBright.black [Error]} There was a problem loading {bold [", "]}."], ["{bgRedBright.black [Error]} There was a problem loading {bold [", "]}."])), configurationPath));
                console.log(ex);
                process.exit(1);
            }
            // configuration must be an object
            if (!configuration_1) {
                console.log(chalk_3.default(templateObject_52 || (templateObject_52 = __makeTemplateObject(["{bgRedBright.black [Error]} configuration at {bold [", "]} is null or not an object."], ["{bgRedBright.black [Error]} configuration at {bold [", "]} is null or not an object."])), configurationPath));
                process.exit(1);
            }
            var include = configuration_1.include || ["assembly/__tests__/**/*.spec.ts"];
            var add = configuration_1.add || ["assembly/__tests__/**/*.include.ts"];
            var flags = configuration_1.flags || {
                "--validate": [],
                "--debug": [],
                "--measure": [],
                "--sourceMap": [],
                /** This is required. Do not change this. */
                "--binaryFile": ["output.wasm"],
            };
            var disclude = configuration_1.disclude || [];
            var reporter_1 = configuration_1.reporter || new DefaultTestReporter_2.DefaultTestReporter();
            var performanceConfiguration_1 = configuration_1.performance || IPerformanceConfiguration_2.createDefaultPerformanceConfiguration();
            // setup performance options, overriding configured values if the flag is passed to the cli
            if (yargs.argv.hasOwnProperty("performance"))
                performanceConfiguration_1.enabled = yargs.argv.performance !== "false";
            // gather all the flags
            if (yargs.argv.hasOwnProperty("maxSamples"))
                performanceConfiguration_1.maxSamples = parseFloat(yargs.argv.maxSamples.toString());
            if (yargs.argv.hasOwnProperty("maxTestRunTime"))
                performanceConfiguration_1.maxTestRunTime = parseFloat(yargs.argv.maxTestRunTime.toString());
            if (yargs.argv.hasOwnProperty("maxTestRunTime"))
                performanceConfiguration_1.maxTestRunTime = parseFloat(yargs.argv.maxTestRunTime.toString());
            if (yargs.argv.hasOwnProperty("roundDecimalPlaces"))
                performanceConfiguration_1.roundDecimalPlaces = parseFloat(yargs.argv.roundDecimalPlaces.toString());
            if (yargs.argv.hasOwnProperty("reportMedian"))
                performanceConfiguration_1.reportMedian = yargs.argv.reportMedian !== "false";
            if (yargs.argv.hasOwnProperty("reportAverage"))
                performanceConfiguration_1.reportAverage = yargs.argv.reportAverage !== "false";
            if (yargs.argv.hasOwnProperty("reportStandardDeviation"))
                performanceConfiguration_1.reportStandardDeviation = yargs.argv.reportStandardDeviation !== "false";
            if (yargs.argv.hasOwnProperty("reportMax"))
                performanceConfiguration_1.reportMax = yargs.argv.reportMax !== "false";
            if (yargs.argv.hasOwnProperty("reportMin"))
                performanceConfiguration_1.reportMin = yargs.argv.reportMin !== "false";
            if (yargs.argv.hasOwnProperty("reportVariance"))
                performanceConfiguration_1.reportVariance = yargs.argv.reportVariance !== "false";
            // if a reporter is specified in cli arguments, override configuration
            if (yargs.argv.reporter || yargs.argv.r) {
                var targetReporter = yargs.argv.reporter || yargs.argv.r;
                // get relative reporters
                if (targetReporter.startsWith(".")) {
                    try {
                        var result = require(path_1.default.join(process.cwd(), targetReporter));
                        // if something is returned
                        if (result) {
                            if (typeof result === "function") { // instantiate it if it's a default exported class
                                reporter_1 = new result();
                            }
                            if (typeof result.default === "function") {
                                reporter_1 = new result.default();
                            }
                            else {
                                reporter_1 = result.default || result;
                            }
                        }
                        else {
                            reporter_1 = new DefaultTestReporter_2.DefaultTestReporter();
                        }
                    }
                    catch (ex) {
                        console.log("Cannot find target reporter at", path_1.default.join(process.cwd(), targetReporter));
                        console.log(ex);
                        process.exit(1);
                    }
                }
                else if (targetReporter === "EmptyReporter") {
                    reporter_1 = new EmptyReporter_1.EmptyReporter();
                }
                else if (targetReporter === "SummaryTestReporter") {
                    reporter_1 = new SummaryTestReporter_1.SummaryTestReporter();
                }
                else {
                    reporter_1 = new DefaultTestReporter_2.DefaultTestReporter();
                }
            }
            // include all the file globs
            console.log(chalk_3.default(templateObject_53 || (templateObject_53 = __makeTemplateObject(["{bgWhite.black [Log]} Including files: ", ""], ["{bgWhite.black [Log]} Including files: ", ""])), include.join(", ")));
            // add a line seperator between the next line and this line
            console.log("");
            var testEntryFiles_1 = new Set();
            var addedTestEntryFiles_1 = new Set();
            // for each pattern
            for (var _i = 0, include_1 = include; _i < include_1.length; _i++) {
                var pattern = include_1[_i];
                // push all the resulting files so that each file gets tested individually
                entry: for (var _a = 0, _b = glob_1.default.sync(pattern); _a < _b.length; _a++) {
                    var entry = _b[_a];
                    // test for discludes
                    for (var _c = 0, disclude_1 = disclude; _c < disclude_1.length; _c++) {
                        var test_2 = disclude_1[_c];
                        if (test_2.test(entry))
                            continue entry;
                    }
                    testEntryFiles_1.add(entry);
                }
            }
            for (var _d = 0, add_1 = add; _d < add_1.length; _d++) {
                var pattern = add_1[_d];
                // push all the added files to the added entry point list
                for (var _e = 0, _f = glob_1.default.sync(pattern); _e < _f.length; _e++) {
                    var entry = _f[_e];
                    addedTestEntryFiles_1.add(entry);
                }
            }
            // loop over each file and create a binary, index it on binaries
            var binaries_1 = {};
            var sourcemaps_1 = {};
            // must include the assembly/index.ts file located in the package
            var entryPath = path_1.default.join(__dirname, "../assembly/index.ts");
            var relativeEntryPath = path_1.default.relative(process.cwd(), entryPath);
            // add the relativeEntryPath of as-pect to the list of compiled files for each test
            addedTestEntryFiles_1.add(relativeEntryPath);
            // Create a test runner, and run each test
            var count_1 = testEntryFiles_1.size;
            // create the array of compiler flags from the flags object
            var flagList_1 = Object.entries(flags).reduce(function (args, _a) {
                var flag = _a[0], options = _a[1];
                return args.concat(flag, options);
            }, []);
            var testCount_1 = 0;
            var successCount_1 = 0;
            var groupSuccessCount_1 = 0;
            var groupCount_1 = 0;
            // for each file, synchronously run each test
            Array.from(testEntryFiles_1).forEach(function (file, i) {
                asc_1.default.main([file].concat(Array.from(addedTestEntryFiles_1), flagList_1), {
                    stdout: process.stdout,
                    stderr: process.stderr,
                    writeFile: function (name, contents) {
                        var ext = path_1.default.extname(name);
                        // get the wasm file
                        if (ext === ".wasm") {
                            binaries_1[i] = contents;
                            return;
                        }
                        if (ext === ".map") {
                            sourcemaps_1[name] = contents;
                            return;
                        }
                        var outfileName = path_1.default.join(path_1.default.dirname(file), path_1.default.basename(file, path_1.default.extname(file)) + ext);
                        fs_1.default.writeFileSync(outfileName, contents);
                    }
                }, function (error) {
                    // if there are any compilation errors, stop the test suite
                    if (error) {
                        console.log("There was a compilation error when trying to create the wasm binary for file: " + file + ".");
                        console.error(error);
                        return process.exit(1);
                    }
                    // if the binary wasn't emitted, stop the test suite
                    if (!binaries_1[i]) {
                        console.log("There was no output binary file: " + file + ". Did you forget to emit the binary?");
                        return process.exit(1);
                    }
                    // create a test runner
                    var runner = new TestContext_1.TestContext(reporter_1, file, performanceConfiguration_1);
                    // detect custom imports
                    var customImportFileLocation = path_1.default.resolve(path_1.default.join(path_1.default.dirname(file), path_1.default.basename(file, path_1.default.extname(file)) + ".imports.js"));
                    var imports = runner.createImports((fs_1.default.existsSync(customImportFileLocation)
                        ? require(customImportFileLocation)
                        : configuration_1.imports) || {});
                    // instantiate the module
                    var wasm = loader_1.instantiateBuffer(binaries_1[i], imports);
                    // call run buffer because it's already compiled
                    runner.run(wasm);
                    count_1 -= 1;
                    testCount_1 += runner.testGroups.reduce(function (left, right) { return left + right.tests.length; }, 0);
                    successCount_1 += runner.testGroups
                        .reduce(function (left, right) { return left + right.tests.filter(function (e) { return e.pass; }).length; }, 0);
                    groupCount_1 += runner.testGroups.length;
                    groupSuccessCount_1 = runner.testGroups.reduce(function (left, right) { return left + (right.pass ? 1 : 0); }, groupSuccessCount_1);
                    // if any tests failed, and they all ran, exit(1)
                    if (count_1 === 0) {
                        var end = perf_hooks_2.performance.now();
                        var failed = testCount_1 !== successCount_1;
                        var result = failed
                            ? chalk_3.default(templateObject_54 || (templateObject_54 = __makeTemplateObject(["{red \u2716 FAIL}"], ["{red \u2716 FAIL}"]))) : chalk_3.default(templateObject_55 || (templateObject_55 = __makeTemplateObject(["{green \u2714 PASS}"], ["{green \u2714 PASS}"])));
                        console.log("~".repeat(process.stdout.columns - 10));
                        console.log("\n  [Result]: " + result + "\n   [Files]: " + testEntryFiles_1.size + " total\n  [Groups]: " + groupCount_1 + " count, " + groupSuccessCount_1 + " pass\n [Summary]: " + successCount_1.toString() + " pass, " + (testCount_1 - successCount_1).toString() + " fail, " + testCount_1.toString() + " total\n    [Time]: " + timeDifference_2.timeDifference(end, start_1).toString() + "ms");
                        if (failed) {
                            process.exit(1);
                        }
                    }
                    return 0;
                });
            });
        }
    }
    exports.asp = asp;
    var templateObject_38, templateObject_39, templateObject_40, templateObject_41, templateObject_42, templateObject_43, templateObject_44, templateObject_45, templateObject_46, templateObject_47, templateObject_48, templateObject_49, templateObject_50, templateObject_51, templateObject_52, templateObject_53, templateObject_54, templateObject_55;
});
define("as-pect", ["require", "exports", "test/TestContext", "test/TestGroup", "test/TestReporter", "test/TestResult", "reporter/DefaultTestReporter", "reporter/EmptyReporter", "reporter/SummaryTestReporter", "util/ActualValue", "util/LogValue", "cli"], function (require, exports, TestContext_2, TestGroup_2, TestReporter_4, TestResult_2, DefaultTestReporter_3, EmptyReporter_2, SummaryTestReporter_2, ActualValue_2, LogValue_3, cli_1) {
    "use strict";
    function __export(m) {
        for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];
    }
    Object.defineProperty(exports, "__esModule", { value: true });
    __export(TestContext_2);
    __export(TestGroup_2);
    __export(TestReporter_4);
    __export(TestResult_2);
    __export(DefaultTestReporter_3);
    __export(EmptyReporter_2);
    __export(SummaryTestReporter_2);
    __export(ActualValue_2);
    __export(LogValue_3);
    __export(cli_1);
});
require("../lib/cli/index.js").asp(process.argv.slice(2));
define("cli/help", ["require", "exports", "chalk"], function (require, exports, chalk_4) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    chalk_4 = __importDefault(chalk_4);
    function help() {
        console.log(chalk_4.default(templateObject_56 || (templateObject_56 = __makeTemplateObject(["\n  {bold.blueBright SYNTAX}\n    {bold.green asp} --init                          Create a test config, an assembly/__tests__ folder and exit.\n    {bold.green asp} -i\n    {bold.green asp} --config=as-pect.config.js      Use a specified configuration\n    {bold.green asp} -c as-pect.config.js\n    {bold.green asp} --version                       View the version.\n    {bold.green asp} -v\n    {bold.green asp} --help                          Show this help screen.\n    {bold.green asp} -h\n    {bold.green asp} --types                         Copy the types file to assembly/__tests__/as-pect.d.ts\n    {bold.green asp} -t\n\n    {bold.blueBright TEST OPTIONS}\n    {bold.green --file=[regex]}                       Run the tests of each file that matches this regex. {yellow (Default: .)}\n      {bold.green -f=[regex]}\n\n    {bold.green --reporter}                           Define the reporter to be used. {yellow (Default: DefaultTestReporter)}\n      {bold.green --reporter=SummaryTestReporter}     Use the summary reporter.\n      {bold.green --reporter=DefaultTestReporter}     Use the default test reporter.\n      {bold.green --reporter=EmptyReporter}           Use the empty reporter. {yellow (This reporter reports nothing)}\n      {bold.green --reporter=./path/to/reporter.js}   Use the default exported object from this module as the reporter.\n\n    {bold.green --performance}                        Enable performance statistics for {bold every} test. {yellow (Default: false)}\n    {bold.green --max-samples=[number]}               Set the maximum number of samples to run for each test. {yellow (Default: 10000 samples)}\n    {bold.green --max-test-run-time=[number]}         Set the maximum test run time in milliseconds. {yellow (Default: 2000ms)}\n    {bold.green --round-decimal-places=[number]}      Set the number of decimal places to round to. {yellow (Default: 3)}\n    {bold.green --report-median(=false)?}             Enable/Disable reporting of the median time. {yellow (Default: true)}\n    {bold.green --report-average(=false)?}            Enable/Disable reporting of the average time. {yellow (Default: true)}\n    {bold.green --report-standard-deviation(=false)?} Enable/Disable reporting of the standard deviation. {yellow (Default: false)}\n    {bold.green --report-max(=false)?}                Enable/Disable reporting of the largest run time. {yellow (Default: false)}\n    {bold.green --report-min(=false)?}                Enable/Disable reporting of the smallest run time. {yellow (Default: false)}\n    {bold.green --report-variance(=false)?}           Enable/Disable reporting of the variance. {yellow (Default: false)}\n  "], ["\n  {bold.blueBright SYNTAX}\n    {bold.green asp} --init                          Create a test config, an assembly/__tests__ folder and exit.\n    {bold.green asp} -i\n    {bold.green asp} --config=as-pect.config.js      Use a specified configuration\n    {bold.green asp} -c as-pect.config.js\n    {bold.green asp} --version                       View the version.\n    {bold.green asp} -v\n    {bold.green asp} --help                          Show this help screen.\n    {bold.green asp} -h\n    {bold.green asp} --types                         Copy the types file to assembly/__tests__/as-pect.d.ts\n    {bold.green asp} -t\n\n    {bold.blueBright TEST OPTIONS}\n    {bold.green --file=[regex]}                       Run the tests of each file that matches this regex. {yellow (Default: .)}\n      {bold.green -f=[regex]}\n\n    {bold.green --reporter}                           Define the reporter to be used. {yellow (Default: DefaultTestReporter)}\n      {bold.green --reporter=SummaryTestReporter}     Use the summary reporter.\n      {bold.green --reporter=DefaultTestReporter}     Use the default test reporter.\n      {bold.green --reporter=EmptyReporter}           Use the empty reporter. {yellow (This reporter reports nothing)}\n      {bold.green --reporter=./path/to/reporter.js}   Use the default exported object from this module as the reporter.\n\n    {bold.green --performance}                        Enable performance statistics for {bold every} test. {yellow (Default: false)}\n    {bold.green --max-samples=[number]}               Set the maximum number of samples to run for each test. {yellow (Default: 10000 samples)}\n    {bold.green --max-test-run-time=[number]}         Set the maximum test run time in milliseconds. {yellow (Default: 2000ms)}\n    {bold.green --round-decimal-places=[number]}      Set the number of decimal places to round to. {yellow (Default: 3)}\n    {bold.green --report-median(=false)?}             Enable/Disable reporting of the median time. {yellow (Default: true)}\n    {bold.green --report-average(=false)?}            Enable/Disable reporting of the average time. {yellow (Default: true)}\n    {bold.green --report-standard-deviation(=false)?} Enable/Disable reporting of the standard deviation. {yellow (Default: false)}\n    {bold.green --report-max(=false)?}                Enable/Disable reporting of the largest run time. {yellow (Default: false)}\n    {bold.green --report-min(=false)?}                Enable/Disable reporting of the smallest run time. {yellow (Default: false)}\n    {bold.green --report-variance(=false)?}           Enable/Disable reporting of the variance. {yellow (Default: false)}\n  "]))));
    }
    exports.help = help;
    var templateObject_56;
});
define("cli/types", ["require", "exports", "chalk", "fs"], function (require, exports, chalk_5, fs_2) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    chalk_5 = __importDefault(chalk_5);
    fs_2 = __importDefault(fs_2);
    function types(assemblyFolder, testFolder, typesFile, typesFileSource) {
        console.log("");
        console.log(chalk_5.default(templateObject_57 || (templateObject_57 = __makeTemplateObject(["[Log] Initializing types."], ["[Log] Initializing types."]))));
        console.log("");
        // Create the assembly folder if it doesn't exist
        if (!fs_2.default.existsSync(assemblyFolder)) {
            console.log(chalk_5.default(templateObject_58 || (templateObject_58 = __makeTemplateObject(["[Log] Creating folder: ./assembly/"], ["[Log] Creating folder: ./assembly/"]))));
            fs_2.default.mkdirSync(assemblyFolder);
        }
        // Create the test folder if it doesn't exist
        if (!fs_2.default.existsSync(testFolder)) {
            console.log(chalk_5.default(templateObject_59 || (templateObject_59 = __makeTemplateObject(["[Log] Creating folder: ./assembly/__tests__/"], ["[Log] Creating folder: ./assembly/__tests__/"]))));
            fs_2.default.mkdirSync(testFolder);
        }
        // Create the types file if it doesn't exist
        if (!fs_2.default.existsSync(typesFile)) {
            console.log(chalk_5.default(templateObject_60 || (templateObject_60 = __makeTemplateObject(["[Log] Creating file: assembly/__tests__/as-pect.d.ts"], ["[Log] Creating file: assembly/__tests__/as-pect.d.ts"]))));
            fs_2.default.createReadStream(typesFileSource, "utf-8")
                .pipe(fs_2.default.createWriteStream(typesFile, "utf-8"));
        }
    }
    exports.types = types;
    var templateObject_57, templateObject_58, templateObject_59, templateObject_60;
});
define("cli/init", ["require", "exports", "chalk", "path", "fs"], function (require, exports, chalk_6, path_2, fs_3) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    chalk_6 = __importDefault(chalk_6);
    path_2 = __importDefault(path_2);
    fs_3 = __importDefault(fs_3);
    function init(assemblyFolder, testFolder, typesFile, typesFileSource) {
        console.log("");
        console.log(chalk_6.default(templateObject_61 || (templateObject_61 = __makeTemplateObject(["[Log] Initializing test suite files."], ["[Log] Initializing test suite files."]))));
        console.log("");
        // create the assembly folder if it doesn't exist
        if (!fs_3.default.existsSync(assemblyFolder)) {
            console.log(chalk_6.default(templateObject_62 || (templateObject_62 = __makeTemplateObject(["[Log] Creating folder: ./assembly/"], ["[Log] Creating folder: ./assembly/"]))));
            fs_3.default.mkdirSync(assemblyFolder);
        }
        // Create the test folder if it doesn't exist
        if (!fs_3.default.existsSync(testFolder)) {
            console.log(chalk_6.default(templateObject_63 || (templateObject_63 = __makeTemplateObject(["[Log] Creating folder: ./assembly/__tests__/"], ["[Log] Creating folder: ./assembly/__tests__/"]))));
            fs_3.default.mkdirSync(testFolder);
            // create the example file only if the __tests__ folder does not exist
            var exampleFile = path_2.default.join(testFolder, "example.spec.ts");
            var exampleFileSource = path_2.default.join(__dirname, "../../init/example.spec.ts");
            if (!fs_3.default.existsSync(exampleFile)) {
                console.log(chalk_6.default(templateObject_64 || (templateObject_64 = __makeTemplateObject(["[Log] Creating file: ./assembly/__tests__/example.spec.ts"], ["[Log] Creating file: ./assembly/__tests__/example.spec.ts"]))));
                fs_3.default.createReadStream(exampleFileSource, "utf-8")
                    .pipe(fs_3.default.createWriteStream(exampleFile, "utf-8"));
            }
        }
        // create the types file if it doesn't exist for typescript tooling users
        if (!fs_3.default.existsSync(typesFile)) {
            console.log(chalk_6.default(templateObject_65 || (templateObject_65 = __makeTemplateObject(["[Log] Creating file: assembly/__tests__/as-pect.d.ts"], ["[Log] Creating file: assembly/__tests__/as-pect.d.ts"]))));
            fs_3.default.createReadStream(typesFileSource, "utf-8")
                .pipe(fs_3.default.createWriteStream(typesFile, "utf-8"));
        }
        // create the default configuration file
        var configFile = path_2.default.join(process.cwd(), "as-pect.config.js");
        var configFileSource = path_2.default.join(__dirname, "../../init/as-pect.config.js");
        if (!fs_3.default.existsSync(configFile)) {
            console.log(chalk_6.default(templateObject_66 || (templateObject_66 = __makeTemplateObject(["[Log] Creating file: as-pect.config.js"], ["[Log] Creating file: as-pect.config.js"]))));
            fs_3.default.createReadStream(configFileSource, "utf-8")
                .pipe(fs_3.default.createWriteStream(configFile, "utf-8"));
        }
    }
    exports.init = init;
    var templateObject_61, templateObject_62, templateObject_63, templateObject_64, templateObject_65, templateObject_66;
});
define("cli/util/IYargs", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
});
define("cli/util/collectPerformanceConfiguration", ["require", "exports"], function (require, exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    function collectPerformanceConfiguration(yargs, performanceConfiguration) {
        if (yargs.argv.hasOwnProperty("performance"))
            performanceConfiguration.enabled = yargs.argv.performance !== "false";
        // gather all the flags
        if (yargs.argv.hasOwnProperty("maxSamples"))
            performanceConfiguration.maxSamples = parseFloat(yargs.argv.maxSamples.toString());
        if (yargs.argv.hasOwnProperty("maxTestRunTime"))
            performanceConfiguration.maxTestRunTime = parseFloat(yargs.argv.maxTestRunTime.toString());
        if (yargs.argv.hasOwnProperty("maxTestRunTime"))
            performanceConfiguration.maxTestRunTime = parseFloat(yargs.argv.maxTestRunTime.toString());
        if (yargs.argv.hasOwnProperty("roundDecimalPlaces"))
            performanceConfiguration.roundDecimalPlaces = parseFloat(yargs.argv.roundDecimalPlaces.toString());
        if (yargs.argv.hasOwnProperty("reportMedian"))
            performanceConfiguration.reportMedian = yargs.argv.reportMedian !== "false";
        if (yargs.argv.hasOwnProperty("reportAverage"))
            performanceConfiguration.reportAverage = yargs.argv.reportAverage !== "false";
        if (yargs.argv.hasOwnProperty("reportStandardDeviation"))
            performanceConfiguration.reportStandardDeviation = yargs.argv.reportStandardDeviation !== "false";
        if (yargs.argv.hasOwnProperty("reportMax"))
            performanceConfiguration.reportMax = yargs.argv.reportMax !== "false";
        if (yargs.argv.hasOwnProperty("reportMin"))
            performanceConfiguration.reportMin = yargs.argv.reportMin !== "false";
        if (yargs.argv.hasOwnProperty("reportVariance"))
            performanceConfiguration.reportVariance = yargs.argv.reportVariance !== "false";
    }
    exports.collectPerformanceConfiguration = collectPerformanceConfiguration;
});
define("cli/util/collectReporter", ["require", "exports", "reporter/DefaultTestReporter", "reporter/EmptyReporter", "reporter/SummaryTestReporter", "path"], function (require, exports, DefaultTestReporter_4, EmptyReporter_3, SummaryTestReporter_3, path_3) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    path_3 = __importDefault(path_3);
    function collectReporter(yargs) {
        var targetReporter = yargs.argv.reporter || yargs.argv.r;
        // get relative reporters
        if (targetReporter.startsWith(".")) {
            try {
                var result = require(path_3.default.join(process.cwd(), targetReporter));
                // if something is returned
                if (result) {
                    if (typeof result === "function") { // instantiate it if it's a default exported class
                        return new result();
                    }
                    if (typeof result.default === "function") {
                        return new result.default();
                    }
                    else {
                        return result.default || result;
                    }
                }
                else {
                    return new DefaultTestReporter_4.DefaultTestReporter();
                }
            }
            catch (ex) {
                console.log("Cannot find target reporter at", path_3.default.join(process.cwd(), targetReporter));
                console.log(ex);
                process.exit(1);
                // @ts-ignore: the process has exited
                return null;
            }
        }
        else if (targetReporter === "EmptyReporter") {
            return new EmptyReporter_3.EmptyReporter();
        }
        else if (targetReporter === "SummaryTestReporter") {
            return new SummaryTestReporter_3.SummaryTestReporter();
        }
        else {
            return new DefaultTestReporter_4.DefaultTestReporter();
        }
    }
    exports.collectReporter = collectReporter;
});
define("cli/util/getTestEntryFiles", ["require", "exports", "glob"], function (require, exports, glob_2) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    glob_2 = __importDefault(glob_2);
    function getTestEntryFiles(yargs, include, disclude) {
        var testEntryFiles = new Set();
        var fileRegexArg = yargs.argv.file || yargs.argv.f || ".*";
        var fileRegex = new RegExp(fileRegexArg);
        // for each pattern to be included
        for (var _i = 0, include_2 = include; _i < include_2.length; _i++) {
            var pattern = include_2[_i];
            // push all the resulting files so that each file gets tested individually
            entry: for (var _a = 0, _b = glob_2.default.sync(pattern); _a < _b.length; _a++) {
                var entry = _b[_a];
                // test for discludes
                for (var _c = 0, disclude_2 = disclude; _c < disclude_2.length; _c++) {
                    var test_3 = disclude_2[_c];
                    if (test_3.test(entry))
                        continue entry;
                }
                // if the fileRegex matches the test, add it to the entry file Set
                if (fileRegex.test(entry))
                    testEntryFiles.add(entry);
            }
        }
        return testEntryFiles;
    }
    exports.getTestEntryFiles = getTestEntryFiles;
});
define("cli/run", ["require", "exports", "assemblyscript/cli/asc", "test/TestContext", "fs", "assemblyscript/lib/loader", "reporter/DefaultTestReporter", "perf_hooks", "util/timeDifference", "util/IPerformanceConfiguration", "path", "chalk", "glob", "cli/util/collectPerformanceConfiguration", "cli/util/collectReporter", "cli/util/getTestEntryFiles"], function (require, exports, asc_2, TestContext_3, fs, loader_2, DefaultTestReporter_5, perf_hooks_3, timeDifference_3, IPerformanceConfiguration_3, path, chalk_7, glob_3, collectPerformanceConfiguration_1, collectReporter_1, getTestEntryFiles_1) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    asc_2 = __importDefault(asc_2);
    fs = __importStar(fs);
    path = __importStar(path);
    chalk_7 = __importDefault(chalk_7);
    glob_3 = __importDefault(glob_3);
    function run(yargs) {
        var start = perf_hooks_3.performance.now();
        // obtain the configuration file
        var configurationPath = path.resolve(process.cwd(), yargs.argv.c || yargs.argv.config || "./as-pect.config.js");
        console.log(chalk_7.default(templateObject_67 || (templateObject_67 = __makeTemplateObject(["{bgWhite.black [Log]} using configuration ", ""], ["{bgWhite.black [Log]} using configuration ", ""])), configurationPath));
        var configuration = {};
        try {
            configuration = require(configurationPath) || {};
        }
        catch (ex) {
            console.log("");
            console.log(chalk_7.default(templateObject_68 || (templateObject_68 = __makeTemplateObject(["{bgRedBright.black [Error]} There was a problem loading {bold [", "]}."], ["{bgRedBright.black [Error]} There was a problem loading {bold [", "]}."])), configurationPath));
            console.log(ex);
            process.exit(1);
        }
        // configuration must be an object
        if (!configuration) {
            console.log(chalk_7.default(templateObject_69 || (templateObject_69 = __makeTemplateObject(["{bgRedBright.black [Error]} configuration at {bold [", "]} is null or not an object."], ["{bgRedBright.black [Error]} configuration at {bold [", "]} is null or not an object."])), configurationPath));
            process.exit(1);
        }
        var include = configuration.include || ["assembly/__tests__/**/*.spec.ts"];
        var add = configuration.add || ["assembly/__tests__/**/*.include.ts"];
        var flags = configuration.flags || {
            "--validate": [],
            "--debug": [],
            "--measure": [],
            "--sourceMap": [],
            /** This is required. Do not change this. */
            "--binaryFile": ["output.wasm"],
        };
        var disclude = configuration.disclude || [];
        // if a reporter is specified in cli arguments, override configuration
        var reporter = (yargs.argv.reporter || yargs.argv.r)
            ? collectReporter_1.collectReporter(yargs)
            : configuration.reporter || new DefaultTestReporter_5.DefaultTestReporter();
        var performanceConfiguration = configuration.performance || IPerformanceConfiguration_3.createDefaultPerformanceConfiguration();
        // setup performance options, overriding configured values if the flag is passed to the cli
        collectPerformanceConfiguration_1.collectPerformanceConfiguration(yargs, performanceConfiguration);
        // include all the file globs
        console.log(chalk_7.default(templateObject_70 || (templateObject_70 = __makeTemplateObject(["{bgWhite.black [Log]} Including files: ", ""], ["{bgWhite.black [Log]} Including files: ", ""])), include.join(", ")));
        // add a line seperator between the next line and this line
        console.log("");
        var addedTestEntryFiles = new Set();
        /** Get all the test entry files. */
        var testEntryFiles = getTestEntryFiles_1.getTestEntryFiles(yargs, include, disclude);
        for (var _i = 0, add_2 = add; _i < add_2.length; _i++) {
            var pattern = add_2[_i];
            // push all the added files to the added entry point list
            for (var _a = 0, _b = glob_3.default.sync(pattern); _a < _b.length; _a++) {
                var entry = _b[_a];
                addedTestEntryFiles.add(entry);
            }
        }
        // loop over each file and create a binary, index it on binaries
        var binaries = {};
        // must include the assembly/index.ts file located in the package
        var entryPath = path.join(__dirname, "../../assembly/index.ts");
        var relativeEntryPath = path.relative(process.cwd(), entryPath);
        // add the relativeEntryPath of as-pect to the list of compiled files for each test
        addedTestEntryFiles.add(relativeEntryPath);
        // Create a test runner, and run each test
        var count = testEntryFiles.size;
        // create the array of compiler flags from the flags object
        var flagList = Object.entries(flags).reduce(function (args, _a) {
            var flag = _a[0], options = _a[1];
            return args.concat(flag, options);
        }, []);
        var testCount = 0;
        var successCount = 0;
        var groupSuccessCount = 0;
        var groupCount = 0;
        var errors = [];
        // for each file, synchronously run each test
        Array.from(testEntryFiles).forEach(function (file, i) {
            asc_2.default.main([file].concat(Array.from(addedTestEntryFiles), flagList), {
                stdout: process.stdout,
                stderr: process.stderr,
                writeFile: function (name, contents) {
                    var ext = path.extname(name);
                    // get the wasm file
                    if (ext === ".wasm") {
                        binaries[i] = contents;
                        return;
                    }
                    var outfileName = path.join(path.dirname(file), path.basename(file, path.extname(file)) + ext);
                    fs.writeFileSync(outfileName, contents);
                }
            }, function (error) {
                // if there are any compilation errors, stop the test suite
                if (error) {
                    console.log("There was a compilation error when trying to create the wasm binary for file: " + file + ".");
                    console.error(error);
                    return process.exit(1);
                }
                // if the binary wasn't emitted, stop the test suite
                if (!binaries[i]) {
                    console.log("There was no output binary file: " + file + ". Did you forget to emit the binary?");
                    return process.exit(1);
                }
                // create a test runner
                var runner = new TestContext_3.TestContext(reporter, file, performanceConfiguration);
                // detect custom imports
                var customImportFileLocation = path.resolve(path.join(path.dirname(file), path.basename(file, path.extname(file)) + ".imports.js"));
                var imports = runner.createImports((fs.existsSync(customImportFileLocation)
                    ? require(customImportFileLocation)
                    : configuration.imports) || {});
                // instantiate the module
                var wasm = loader_2.instantiateBuffer(binaries[i], imports);
                if (runner.errors.length > 0) {
                    errors.push.apply(errors, runner.errors);
                }
                else {
                    // call run buffer because it's already compiled
                    runner.run(wasm);
                    testCount += runner.testGroups.reduce(function (left, right) { return left + right.tests.length; }, 0);
                    successCount += runner.testGroups
                        .reduce(function (left, right) { return left + right.tests.filter(function (e) { return e.pass; }).length; }, 0);
                    groupCount += runner.testGroups.length;
                    groupSuccessCount = runner.testGroups.reduce(function (left, right) { return left + (right.pass ? 1 : 0); }, groupSuccessCount);
                }
                count -= 1;
                // if any tests failed, and they all ran, exit(1)
                if (count === 0) {
                    var end = perf_hooks_3.performance.now();
                    var failed = testCount !== successCount || errors.length > 0;
                    var result = failed
                        ? chalk_7.default(templateObject_71 || (templateObject_71 = __makeTemplateObject(["{red \u2716 FAIL}"], ["{red \u2716 FAIL}"]))) : chalk_7.default(templateObject_72 || (templateObject_72 = __makeTemplateObject(["{green \u2714 PASS}"], ["{green \u2714 PASS}"])));
                    console.log("~".repeat(process.stdout.columns - 10));
                    for (var _i = 0, errors_1 = errors; _i < errors_1.length; _i++) {
                        var error_1 = errors_1[_i];
                        console.log(chalk_7.default(templateObject_73 || (templateObject_73 = __makeTemplateObject(["\n [Error]: {red ", "}: ", "\n [Stack]: {yellow ", "}\n"], ["\n [Error]: {red ", "}: ", "\n [Stack]: {yellow ", "}\n"])), error_1.type, error_1.message, error_1.stackTrace.split("\n").join("\n            ")));
                    }
                    console.log("\n[Result]: " + result + "\n [Files]: " + testEntryFiles.size + " total\n[Groups]: " + groupCount + " count, " + groupSuccessCount + " pass\n [Tests]: " + successCount.toString() + " pass, " + (testCount - successCount).toString() + " fail, " + testCount.toString() + " total\n  [Time]: " + timeDifference_3.timeDifference(end, start).toString() + "ms");
                    if (failed) {
                        process.exit(1);
                    }
                }
                return 0;
            });
        });
    }
    exports.run = run;
    var templateObject_67, templateObject_68, templateObject_69, templateObject_70, templateObject_71, templateObject_72, templateObject_73;
});
define("cli/index", ["require", "exports", "chalk", "path", "yargs-parser", "cli/types", "cli/init", "cli/help", "cli/run"], function (require, exports, chalk_8, path_4, yargs_parser_2, types_1, init_1, help_1, run_1) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    chalk_8 = __importDefault(chalk_8);
    path_4 = __importDefault(path_4);
    yargs_parser_2 = __importDefault(yargs_parser_2);
    var pkg = require("../../package.json");
    /**
     * This is the cli entry point and expects an array of arguments from the command line.
     *
     * @param {string[]} args - The arguments from the command line
     */
    function asp(args) {
        // parse the arguments
        var yargs = {
            argv: yargs_parser_2.default(args),
        };
        // Skip ascii art if asked for the version
        if (!(yargs.argv.v || yargs.argv.version)) {
            console.log(chalk_8.default(templateObject_74 || (templateObject_74 = __makeTemplateObject(["{bold.bgWhite.black ", "       ___   _____                       __  \n      /   | / ___/      ____  ___  _____/ /_ \n     / /| | \\__ \\______/ __ \\/ _ \\/ ___/ __/ \n    / ___ |___/ /_____/ /_/ /  __/ /__/ /_   \n   /_/  |_/____/     / .___/\\___/\\___/\\__/   \n                    /_/                      }\n  \u26A1AS-pect\u26A1 Test suite runner {bgGreenBright.black [", "]}\n  "], ["{bold.bgWhite.black ",
                "       ___   _____                       __  \n      /   | / ___/      ____  ___  _____/ /_ \n     / /| | \\\\__ \\\\______/ __ \\\\/ _ \\\\/ ___/ __/ \n    / ___ |___/ /_____/ /_/ /  __/ /__/ /_   \n   /_/  |_/____/     / .___/\\\\___/\\\\___/\\\\__/   \n                    /_/                      }\n  \u26A1AS-pect\u26A1 Test suite runner {bgGreenBright.black [", "]}\n  "])), "", pkg.version));
        }
        var assemblyFolder = path_4.default.join(process.cwd(), "assembly");
        var testFolder = path_4.default.join(assemblyFolder, "__tests__");
        var typesFileSource = path_4.default.join(__dirname, "../../assembly/__tests__/as-pect.d.ts");
        var typesFile = path_4.default.join(testFolder, "as-pect.d.ts");
        if (yargs.argv.t || yargs.argv.types) {
            types_1.types(assemblyFolder, testFolder, typesFile, typesFileSource);
        }
        else if (yargs.argv.i || yargs.argv.init) {
            // init script
            init_1.init(assemblyFolder, testFolder, typesFile, typesFileSource);
        }
        else if (yargs.argv.v || yargs.argv.version) { // display the version
            console.log(pkg.version);
        }
        else if (yargs.argv.help || yargs.argv.h) { // display the help file
            help_1.help();
        }
        else { // run the compiler and test suite
            run_1.run(yargs);
        }
    }
    exports.asp = asp;
    var templateObject_74;
});
//# sourceMappingURL=as-pect.amd.js.map